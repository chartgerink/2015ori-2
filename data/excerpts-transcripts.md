# 19e

> it or something. But, yeah, then I thought using a large data set and treat it as
some kind of population and sample from that 25 subjects would be a better
way to maybe avoid detection. Yeah, that was my reasoning.

> looked at the mean of the means, the standard deviation of the means, the mean
of the standard deviations of the - standard deviations. And then, I thought,
well, what else could you guys use to detect fraud and then I thought, maybe
there is something known in the Stroop task about the correlation between
those measures. Probably, there is - I don’t know. So, I also looked at the
correlation between those four measures, right - mean and standard deviation
from the two condition. And then I generated a new 121 sized data set with
those characteristics. So, just in R - I just generated a correlated data set with

> template. Then, manually, I checked for crazy outliers - like I don’t know -
maybe, there were response times of below 100 milliseconds and that would of
course be not possible. But there weren’t any. So, then I decided that that

> P: Not really. I am just very curious as to the methods that other people used.
I mean, I was thinking about, maybe, I should use like an LCA model or an
LBA model to generate data. And I thought: No, I am way overthinking it. It
doesn’t have to be that hard, I guess.

> P: Yeah, because it is, I guess, fun to do something that is really not allowed
in science. And yeah, I mean, I think [REDACTED] also did it and was like

> that sounds like a good challenge. Wonder if I can beat [REDACTED] with
generating data. So, yeah, it seemed like a fun challenge.

> were interested in participating but I think we are too competitive to actually
discuss our methods with each other.

# 1se

>P: No. But I did recruit one of the postdocs.

>P: To discuss how we could do this.

>P: So, I didn’t do this on my own. I recruited additional help.

---

> congruent trial and [?] some 2-300 milliseconds longer. So, there is kind of a
range of plausibility that you can extract from the literature. If the latencies
would be completely off - like by a factor(?) of 5 or 10 - then something surely
must be a miss. So, distribution, absolute values, and the lack of outliers - this
would be, I think, hallmarks of fabrication. That’s what I look for when I get
students’ work. So, that is probably why I come up with these.

---

> P: Of course. We started out with great reluctance not wanting to fake data but
once we accepted the mission we really wanted to make sure that you couldn’t
detect our playing this game. So, yes, we tried to think about how we could
make the data look real.

---

> P: Yeah, we took into account the fact that the absolute latency has a relationship
with the standard deviation. If you are very slow then the standard deviation
will be a little bit longer. So, there was a correlation between the mean and the
standard deviation introduced.

---

> P: No, I don’t think we - we just - I think, we just looked at whether we didn’t
completely miss - just the very very eye balling - rough eye balling whether
everything looked sort of ok-ish. But no, no formal checks if the value is like 2%
outside of the original means we do it again until . . . That, we didn’t do. We
didn’t iterate the process. Just did it one time. We wanted to beat the system
but not spend too much time. Basically, that is what happened.

---

>P: No. It was more thinking about which approach would be most hard to detect.
No, it is not difficult to fabricate data, unfortunately. But it is difficult probably
to fabricate data that look like real data. That is not an easy task.

---

<!-- nothing to hide argument88 -->
> really meant for improving science etc. So, my first gut instinct was: I am not
going to fabricate data. That is really bad. But I understand why it is necessary
that we actually increase our ability to detect fabricated datasets that will be
in the benefit - in the long-term benefit of science. That is basically it. And
furthermore, since - although you never know for sure - neither I nor anybody of
my team has ever fabricated data I am much in favor of catching those who did.
We have nothing to fear from a good data fabrication detection system. So, that
is why I ultimately thought, of course, I should participate.

---

