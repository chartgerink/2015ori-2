Yes.
So, more educational psychology.
No. Oh, sorry any experiments or a Stroop task experiment?
I have not conducted a Stroop task experiment.
So, during my Bachelor and Master education, we did the Stroop task ourselves and we saw it a lot. 
Yes. So, I knew about it from my studies. But I did refresh my memory, I did look up a paper on the Stroop task for this data fabrication.
Just SPSS and R.
I would say a 7.
6.
So, I started out - you could say I spread it over 2 days, but actually, yesterday when I tried to find the work I originally did, I couldn't find it anymore. So, I started again. So, I did it all in one day.
In total about 2.5 to 3 hours.
Yes, only to yesterday. So, yesterday 2.5 hours and then the first day I think about an hour.
A 6.
Yes.
About 30 to - well, so, on the preparation before I started the process of generating the fabricated data, I spent about 30 to 45 minutes where I found a paper, picked out some tables, looked at response latencies, and made some notes, and thought ok, so, if I would fabricate data, what kind of distribution would I want to sample from, what should be the bounce, things like that, yeah.
No, I didn't read literature on data fabrication detection. Only on the Stroop task.
No, no. Like I know about the Stapel affair and data fabrication things, but I didn't look at literature about it. No, I don't know how they found it.
Yes. So, I used - I looked up 3 papers. but I ended up using 2. And in one paper - one paper did several experiments with the Stroop task and they had some tables with means and standard deviations for the response latency in the congruent and incongruent conditions. And so without looking at the rest of the experiment, I looked at all these different tables to get a feel of what is kind of the minimum mean and what is kind of the maximum mean of the response latency in the two conditions, what is about the size of the standard deviations for these two conditions in each one. And the other paper had some nice figures with distribution of the response time latency, so it made me decide kind of that the standard deviation for the incongruent condition should be a little bit larger than the standard deviation for the congruent condition. That is, what I got out of looking at - and it made me decide kind of what the bounce of the response latencies would be.
No.
So, if the means and standard deviations look a lot alike or if there is like one mean and a super small standard deviation, I would say that would be suspect. [REDACTED] but those kinds of clues would be what I would look for: striking similarities.
No.
Yeah, so I did because I - for each respondent I sampled from - I took a sample from a different population mean and standard deviation. So, the first thing I did was generate kind of the setup so that I would have for each person a different underlying population mean.
Yes.
No. So, I did try to kind of google what the correlations within a person would be between the conditions, within-person variability, but my R knowledge is not good enough that I could take that into account in the sampling design. So in the end, yeah, I did spend a couple of minutes looking into whether I could take that into account, but then I thought, this is going tol take too much time. I don't think I can - That would take me a good other day to figure out how to sample that while taking the within-person relations into account. So, I didn’t do that.
So, I didn’t think about – so, on purpose, I didn’t try to create a mean myself. So, first - I just tried to randomly sample as much as possible, because I thought if I myself start to fill in means, I am gonna go 50 above, 50 below, it is gonna be systematic. So, that is why I used R.
Yes, I did. So, I used – it is in the R code as well which I provided – yeah, so I had means for the congruent condition the underlying population means were between 500 and 700 and for the incongruent condition between 650 and 900 and then the standard deviations for the congruent condition, I sampled them from between 70 and 130 and for the incongruent condition between 100 and 160. So, those were my starting values and then for each person - so for each person, I combined these 25 sampled means and standard deviations per person. And then for each person, I sampled from a normal distribution with basically the first mean of the congruent condition and the first standard deviation of the congruent condition, I sampled 30 observations. And then for the incongruent condition, I sampled with the second incongruent mean and standard deviation and I also sampled 30 observations and then I just computed the mean and the standard deviation and then I repeated that for everyone.
I would say the correlations between - the correlations within person.
I don't think so.
Yeah. So I sampled from a uniform distribution 25 population means for the congruent condition and 25 population means for the incongruent condition. I used those values that I sampled to sample 30 observations per person in each condition from a normal distribution.
I got the values independent from each other.
So, I also generated some population standard deviations by sampling from a uniform distribution between two sets of values. So for the incongruent condition, I sampled the standard deviations from a uniform distribution between 100 and 160. And then for each participant, I used those as the standard deviation to sample all of their standard deviations. I guess, I don't know (?).
No, I only did one run. 
Yes, because I thought if I start to look at it and tweak it, I am introducing systematic - I was afraid I would introduce some systematic miss (?) so I thought I just let R do the work.
I mean I looked at it and sometimes I thought, well that is kind of an extreme mean, so I don't know if that is good, but then I didn't do anything with that thought. So, I did look at the results.
No, no.
No, so here I have these random draws and then I computed the mean and the standard deviation. I did that for every person. I didn't put it underneath each other and I didn't inspect it in any other way
So because I - so, I used unique means and standard deviations for every person in every condition.
Yes.
No, no, I didn't change it, no. I round it.
I used R.
Yes.
No. I mean, I was inspired by reported real results. I didn't use real data.
Yes. So, I looked at these papers and I did a print-screen (?) of kind of what their figures and tables looked like. And then I decided what to do.
No.
No.
Medium, medium. I didn't think it would be easy, but I also thought it would be doable enough, yes.
I found it - I mean, I think the most difficult thing was deciding on how to approach the task and which kinds of values to use for the means and the standard deviations. I think that was a lot of effort. I have been learning a lot more about R in the last few months, so I was fairly confident that I could do a basic - that I could fabricate it relatively easily in R. So, I wasn't worried about the R part of the actual generation, but it took more effort to decide what kinds of means and standard deviations.
I mean I considered just thinking of means and standard deviations myself, but I thought that would be too difficult, because then I would think every time, I don't know if this looks too much like the other one. And then - I think that would have - yeah, I started off doing that and then I thought no, it is too difficult.
I don't know. Honestly, I don't know. I hope so because there is a nice bonus if it is. But I don't think so. Maybe because I didn't take into account everything.
I don't know. I guess maybe if they see the data and if they are like super experts on the topic, then maybe they would see, that is a strange value, like no one has a mean of 900 for a particular condition or something. So, that could be the case. Maybe if they compute correlations and find a super low correlation between people, I mean within-people, maybe that would be an indication that it is not real.
Because I thought it would be really interesting. I think the topic is really cool and really relevant. So, I think it is really important to contribute to this kind of research. Yeah, also in doing meta-analysis it is kind of - I really realized the importance of methodological quality in research. And, yeah, so I think it is really important that you guys have data from real fabrications in order to test some methods. Because I think that type of methodological research is not done very often. So, I think it is really relevant.
[REDACTED]. So, I definitely did talk to them about [REDACTED]. 
No, it was just a discussion of whether we would and it is interesting.
[?]
No, I think I explained everything. I don't think there is anything else to add.
