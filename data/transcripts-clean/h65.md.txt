I am a PhD student, yes.
Experimental, so cognitive psychology, yeah.
No, not a Stroop task.
I believe during my Bachelor in psychology I've learned about the Stroop task and I think I programmed one once for a course and that's it.
Yeah, I have read a couple of papers, the original by Stroop as well.
I mainly use R and Python, yeah.
I would say about an 8.
I am quite confident. I would say an 8 as well, yeah.
I did it in one day.
I think it took me about 10 hours, everything together. 
I would say about a 4, yeah, so about half way, yeah.
Yeah, I discussed it with colleagues like how they would approach the problem and I have talked to a lot of different people. So, I tried to incorporate different aspects into it, yeah.
On preparing, I think, about 5 hours, yeah.
No, I haven't.
No, I actually haven't, no.
Yeah, so my first instinct was to generate the data using some kind of a model like a model participant. That's what I went for in the end. And how - the other things I considered was doing it by hand - and just filling in values by hand - or using data I have lying around and change it around a bit. So, using real data, but then just, yeah, re-using it basically. Those were kind of the three approaches I have considered.
Yeah with reaction times and just changing them a little bit.
No.
Yeah, it did. But what it mainly did was it influenced my approach into generating the data, the thing I did in the end. Like you should make sure you watch out for these kind of things. Yeah, there are a couple of steps that I didn't think of myself my colleagues thought about, so I could incorporate.
Well, the reason is that I thought, this would be the most difficult to detect, because I basically - I generated data that should be very similar to how we make statistical models of data, so I think that is very difficult to distinguish from real data. And I also think this would be the least susceptible to, yeah, me making manual errors, repeating numbers or something like that, some kind of repeating pattern that I would do as a person, right. Yeah, so that is why I chose for this. I think this would be the hardest to detect.
Timeline, I - yeah, no, I think, no not timeline-wise. Sorry, I just had to think for a little bit, but no timeline wise I think we are good. I did spend quite a bit of time looking at the data, so plotting the data. Instead of 25 participants I just plotted - I generated 25 000 participants and plotted how the data looked and if it looked convincing to me. So, there was a bit of post-generation checking if everything was working ok. About 2 hours for that.
What would to me make data look more fabricated is especially if you have 25 participants if all participants show the same direction of the effect. So if the within-subject effects are very similar to each other that would to me signal that someone has been fabricating data. Or repeating numbers, like repeating patterns of numbers, because it is so unlikely that you will find 498.8 multiple times something like that, right? So, yeah, I think that would indicate to me that data is not real. Or the person (?).
Well, I think that is also a little bit with the design of this that you just give means and standard deviations per participant. I think it is quite hard to tell if the data is genuine. I would be more convinced if you had trial-by-trial - because we were supposed to simulate 30 trials - if you had the trial-by-trial data I think it would be easier to see – for me at least- if the data looks genuine. So, raw data would be the answer to that for me.
Based on what - yeah, so, I think also on previous findings if it is something I know about, right. So if I - I personally look into inhibition (?) of return if I would find an inhibition of return effect that is larger than 30 milliseconds or something like that I would say this not - you did something - I would assume that someone did something wrong rather than fabricated their data, but, you know, that would indicate to me that something is up - if the magnitude of the effect isn't ok. And the raw data, yeah, if, I don't know, the amount of participants doesn't match up and that kind of stuff like, yeah, I think there is - or if the labels on the - when the data was being recorded doesn't match with the period of time that they recorded the data in, that kind of stuff would signal to me that there is something fishy going on.
Well, mainly that - well, what I took into account was that I shouldn't do stuff manually, because if I do it manually, you might be able to detect in pattern how I am entering stuff. So, I thought I should do this with a computer and not touch it myself at all. And make a very convincing model participant, but don't type in the Excel sheet myself. That was my main consideration.
Yeah, the relations that I took into effect were the relation between mean and standard deviation – that typically if you find a larger mean you also find a larger standard deviation. And the relation that - so I sampled the data from a normal distribution but that the within-subjects effects aren't sampled separately so that you don't sample from a normal distribution for the congruent condition and a normal distribution for the incongruent condition, but you sample from a normal distribution for the congruent condition and then the difference with the congruent condition that you sample from that, because otherwise there is no relation between the one condition and the other, right. So then it will - if you would draw it in a point cloud the point cloud would just be circular and it is supposed to be a little bit - there is supposed to be a little bit of correlation between the two conditions. So, those are the two things I took into consideration.
If - yeah, so I found some papers on Stroop task effects and I generated my data according to one paper and then I looked at other papers if it matched up. And it matched up quite well, so I thought this is a good thing. Also, I plotted the data as I said earlier to kind of get a sense of did it look too uniform or did it look like there was variation in there, so yeah.
Sorry, could you specify what you mean by that?
Well, yeah, I got all my - yeah, I got my criteria basically from papers. So, if the Stroop task paper matched my generated data, then I would find that pretty convincing. Yeah, that basically.
Ok. Yeah, criteria would be that the - so that the mean and standard deviations that I generated were pretty similar to what they found. Some papers actually include participant-data, so you can look at the distribution a little bit and compare. So, I did that. And also to kind of get an idea of the consistency of the effect. The effect is quite consistent as well, which helps in fabricating the data. So, that means you don't need to add too much noise to your sample to make it look more convincing. So, I looked at that like how consistent is this effect and, yeah, what are the means and standard deviations typically found.
Well, in hindsight, if I would have done it again, I think, I would have - what I did now is I generated means and standard deviations, but I think I would have made a model of a participant like what might be going on within the participant. But that would be a lot of more complex, that would take a lot more steps. Like including like what happens if the participant - the fake participant would guess or doesn't see it has a lapse or something like that, so model that in there as well. I think I could have made a more complex participant-model, but I think this [?], but in hindsight, I would have liked it to be a little more complex than it is.
Yeah, so mainly with regard to the participant itself. Also having - sort of having guesses or well guesses, lapses in this case then. So that participants weren't paying attention and pressed to late or that participants press really quickly without really paying attention to this stimulus, where they just sometimes reflexively respond participant or what happens as well that if you present the same color multiple times, then participants will get quicker, as there is this effect of the sequence as well. So, I think for an accurate - or for a very convincing model of a participant, you need to include all those different parameters in there, yeah.
Yeah, one thing that I didn't mention is that - or are you gonna still ask about how specifically I generated the data.
Ok, then I am good.
Ah, perfect.
Yeah. I could actually look it up as well, but what I did - I think I have it open somewhere - if I can find it, sorry, let me just ...
[REDACTED]. Yeah, so what I did is that I specified the mean for congruent condition, which I found from one paper, and then I looked at a couple of papers what typically the difference in means is for a congruent and an incongruent condition. And I specified that. And I think the mean here that I used is 672 and I found that the difference between the two conditions is about 50 - is it milliseconds - yeah, milliseconds on average. And that, yeah basically, that.
Yeah, so I used a two-dimensional Gaussian to sample the mean and standard deviation from. So, basically, there is a certain amount of correlation between the mean and standard deviation. So if you would draw it in a plot, you would get kind of an ellipsoid function. So, I kind of played with that until it looked about right. And then, I did the same for the difference in mean and difference in standard deviation between the congruent and incongruent conditions to make sure that there was a weak correlation between everything. And yeah, I sampled that - I sampled from that distribution for every participant basically and added some random noise to it.
Yeah.
Yeah, yeah, ok, I kind of just - I just did that, but the standard deviations I didn't specify. I used a standard deviation of about 130, I think, and then I said in the incongruent condition, that's about 10 higher. So, that's the values that it should be centered around, yeah.
Yeah, so, I fabricated the data in a very - with high participant numbers, just so that you can plot all of the distributions and to see if there is enough variance there. And if everything is going ok. And I think it did that about 20 times, before I was satisfied with my model and reduced it down to 25 and put it in an Excel file.
Yeah, so I - well, for one, if there were no like things that I - some kind of artefacts. For example, the random noise putting that in was that was a bit tricky. What it does now is that it determines for each participant a magnitude of noise between 0 and 1, where 1 is just complete random noise and 0 is perfectly sampled from a distribution. So, that was a bit tricky to get that right because if that is correlated with each other, then you don't get these ellipsoid clouds of or ellipsoid relation between the mean and standard deviation, but you get these kind of crosses, you get kind of these axes, these weird shapes that I think would be very detectable if you looked at it. So, I made sure there was nothing weird in that. And then once I got the distribution right I looked at papers to see if it matched the distributions I found in papers. And once it did, I was satisfied.
Yes, so by plotting mainly, yeah.
Yeah as well – what I mainly looked at if – because typically if you test about 25 participants, there should be 2 participants or so that are a bit weird or not quite showing the effect or not even not showing the effect but are just doing something that doesn’t quite make sense. At least that is from my experience. So I made sure that there is enough noise in there, that there is at least 2 participants that are kind of like [?], so yeah.
Actually, in this case, I just - I followed kind of a gut feeling from like spending quite a bit of time of looking at data. I didn’t quite think about – I am sure I could have objective it somehow, maybe tests of normality or something like that, but it is a little bit not completely normal – normally distributed. But I didn’t do that. It looked good to me, so then I figured, ok, I think this is going to give you tough enough a job as it is. 
So, well, yeah, so doing it with 25 participants, I think I did it about 4 times before I was satisfied.
Yeah, I used Python to generate the data.
Yeah, so this would be sampled from a random number generator, so yeah.
No, there is no real data.
No, no, that is correct. I was, yeah, inspired by the real data, tried to do what the statistics are doing on the real data and see if it looked convincing.
Let me look if I mentioned everything. Yeah, I mentioned about everything, so.
No, I didn’t find it very difficult. I did find it – what I found most difficult was just thinking about how are you going to find out that this is fake. I wasn’t really thinking about – yeah, in a sense I wasn’t trying to make convincing data, I was trying to make data that you can’t distinguish from real data. That was kind of my goal. So, I was really thinking like what – how are you going to look at this? How are you going to try to detect that this isn’t real data?
Yeah, so mostly statistically what we were thinking about. So that you would look at if there was a relation between mean and standard deviations, for example, because if that is not there, that is weird, because there should be some kind of correlation between that. And also at the within-subjects effects as I mentioned previously that they should make sense so if someone scored quite - if someone had a quite slow reaction time, that would have an effect on their - quite slow reaction time on the congruent condition, that would have an effect on their incongruent condition as well if the size of the within-subject effect - so, I was thinking in those terms like what can you do, because means and standard deviations, it is not that much information to go on for you guys, I think. So, I was just trying to think like ok what – statistically, what can you try to get out of this? Yeah, that was my reasoning.
I think so, personally, yeah.
Well, my reasoning was that if this is - basically, the statistics we use do certain assumptions about the data and if I use those assumptions to generate data and add noise to it, I think it would be statistically very difficult to distinguish it from real data, because this is - these statistics make the model of the data, [?] it is normally distributed and compare to those two normal distributions to each other. If I basically reverse-engineer that and add some noise to it, that should be very difficult to detect in my opinion, at least with my line of reasoning.
Well, I was thinking - well, the fact that you mentioned a random number generator worried me slightly, that you might find some kind of pattern in that, that you could find the seed of it somehow. I have no idea but, yeah, so that would be – that’s worrying me now a little bit. I didn't consider that. And what else could you do? I am thinking that maybe there is some kind of information in the Excel sheet if that makes any sense - if it has been copy-pasted into it or something like that all in one go, that would be a bit suspicious. I don't know if you could retrieve that somehow. But other than that, no.
I thought it was quite fun, actually. I just - [REDACTED], so I decided to sign up, because it sounded like a good exercise for myself as well to see like whether I understand statistics enough to reverse-engineer this, so it was an exercise for myself. Yeah, and it just seemed like fun.
Yeah, so with some colleagues [REDACTED].
Well, conceptually yes, but I have programmed it all myself.
I think, another colleague of mine [REDACTED] is also participating in this study. So, I think another colleague of mine, but I didn't really discuss it with him. So, that's the one colleague I didn't discuss it with, coincidentally.
Yeah, exactly. Different approaches. And then I would be like this would be my approach, would that be convincing to you? And then it kind of went back and forth until we were like ok. But yeah, in one sense, we all kind of approached the problem from the same angle which is statistical. We would be thinking how is this statistically indistinguishable, so yeah.
No, not really, no.
Anything I can recall that is worth mentioning? No, I don't think so, no.
