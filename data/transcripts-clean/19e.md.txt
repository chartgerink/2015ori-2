Eh, yeah. Well, I just finished my dissertation but yeah, officially, I am still a PhD student.
Then, I would say cognitive psychology.
I have but not for my dissertation. So, for example, I used to be a research assistant as well and I collaborated on collecting Stroop data. But I have not used the studies myself in my publications.
Yes, yes. Of course with regular Stroop task, the analysis is quite straightforward, right. It is just comparing the incongruent to the congruent trials and calculating this congruency effect. I have never used, like for example, an emotional Stroop task or other adaptations of the Stroop task. I have only worked with the regular Stroop task. So, in experimental settings such as as a research assistant but also as a clinical interviewer that I used to - I used to work at the [REDACTED] for the [REDACTED]. I am not sure if you are familiar with it. [REDACTED]. And there we had the classical Stroop task with reading out words from a piece of paper. I also collected those data.
Right. So at least once a week, I would say R and Python.
A 5 being average?
I don't know. Probably a 7 or something.
I don't know. Probably a 5. I don't have the feeling that - I mean they are all knowledgeable people who were trying to fabricate these data, of course. So, I would say a 5. I don't think I would do any better or worse than my peers.
No, I did it in one day.
I guess about 3 hours. So, part of what I did was I had to find a large sample data set of Stroop data and that took a while to find on the internet. Because my own data is like with small groups and I wanted a large data set. So, I had to look on the internet to find one.
I would say 4. I mean it was more difficult than I expected. It took some thinking as to what would constitute a good fabricated data set. But, yeah, I would say a 4 out of 7.
No, not really.
No, no. I guess I should have. That is a good idea. But I didn't, no.
No, I just - I read a few meta-analyses on the Stroop effect. Hopefully, that gave me some insight. But no, I did not look at the literature on data fabrication itself.
Ja.
So, first I was like, well, what I of course could do is just look at my own old data. Just look at the means and standard deviations or maybe do even the calculations per subject. And just try to - I don't know - throw some noise over it or something. But, yeah, then I thought using a large data set and treat it as some kind of population and sample from that 25 subjects would be a better way to maybe avoid detection. Yeah, that was my reasoning.
Oh, yeah probably. Yeah, yeah definetely. I mean, the first option would be easier, I guess. But yeah, I think the approach that I took now would be less easy to detect.
No, the timeline was pretty straightforward. I just put a block of - I think - four or six hours in my calender and just devoted it to this thing.
I guess, repetition of data would constitute - would be evidence for fabrication. I think the best indicator for fabrication would be means or standard deviations that would not be similar to what has been found in earlier studies. And yeah, of course, I also asked that myself: What would you guys use to try to detect data fabrication? And of course that have to be measures on the data, on the - like in the format that you actually wanted the data to be collected. So, yeah, whatever measures you were using to detect fabrication it has to work on the means and standard deviations of 25 subjects. So, I thought means and standard deviations, maybe even cross-correlations between those measures. So, those were actually the measures that I used to fabricate my data.
I guess - I would probably say that distributions .... So, with data fabrication what you  - what you would see, I guess, is that the distributions would be similar to a standard Gaussian or another standard distribution. Whereas, of course, real data is not perfectly distributed. So, I think you would see in genuine data deviations from perfect distributions.
The last - so, the distribution of the data I did not really take into account because in the sample data set that I found online on many subjects - all the measures looked pretty normally distributed. So, I did not go through the effort of - I don't know - adjusting my distributions. I just treated them as normally distributed. But I guess for a lot of measures you would not find data that clean.
Yeah. I definitely took those into account. So, I looked at the - yeah, I made sure that my fabricated data set would show the same intercorrelation between all variables. The same mean and standard deviation of means and standard deviation and standard deviation of standard deviations.
No.
Yes, so like I said. I compared the characteristics of my data - so, the mean of means and the standard deviation of means, mean of standard deviations, and standard deviation of standard deviations and all the cross-correlations between those measures - and I made sure that they were quite similar to in the real data set that I found.
Well, I guess, if you wanna use bootstrapping you could probably get closer to your - to the characteristics of the genuine data that I looked at. But I did not do that. I thought that my data was good enough. But I am pretty sure that there are better ways to do it.
No, I think we get to the data fabrication later, right?
Yeah. So, I wrote down the whole procedure and - so what I did - and I will run you through what I did and then you can decide if I answered your question. So, what I first did is I went looking for a large data set on the Stroop task with a lot of subjects, more than 25. So, that took a while and then I found a sample Stroop data set with 121 subjects and I thought ok, that's enough. And what I then did is per subject calculate the means for the two different conditions and the standard deviations for the two different conditions - basically the format that you provided in your template - per subject. So, that left me with 121 means and standard deviations for two conditions. Then, I looked at the data characteristics. So, first I looked at the distribution of the data and like I said that looked pretty normal. So, I didn't go through the effort of doing anything weird with distributions or skewing it or anything. Of course, I looked at the mean of the means, the standard deviation of the means, the mean of the standard deviations of the - standard deviations. And then, I thought, well, what else could you guys use to detect fraud and then I thought, maybe there is something known in the Stroop task about the correlation between those measures. Probably, there is - I don't know. So, I also looked at the correlation between those four measures, right - mean and standard deviation from the two condition. And then I generated a new 121 sized data set with those characteristics. So, just in R - I just generated a correlated data set with the given correlations and the mean and standard deviation of the means and standard deviations. Giving me a 121 sized data set with those characteristics. From that data set, I sampled randomly 25 subjects. Or I think it was 25 that you want, right? I randomly sampled 25 subjects and I put them in your template. Then, manually, I checked for crazy outliers - like I don't know - maybe, there were response times of below 100 milliseconds and that would of course be not possible. But there weren't any. So, then I decided that that would be a good fabricated data set.
Yeah, it is like I said I just used a random number generator that of course just generates a Gaussian with a given mean and standard deviation. So, I did not do anything special to generate mean and standard deviation. The only constraints were of course the correlations between the variables. But there is a nice R package to build correlated data sets.
Yeah, I just googled 'stroop.csv'. And at some point, I came up to this website that I think for a statistics course offered a sample Stroop data set collected on 121 students. So, I thought, well, that looks good.
No. It actually only took one try. Apparently, my random number generator is good enough to generate data sets that are pretty close to the constraints that I set. But of course, if the constraints wouldn't have been met, I would just have repeated the procedure and probably would have found a good data set.
Yeah, so I just looked at the mean and standard deviation and the mean and standard deviation of the mean and standard deviation of the sample data set, of my own data set and they looked pretty similar. I did not have a fixed threshold that I used but the numbers were pretty close. So, then I was satisfied. And then, yeah, like I said for the 25 samples I took I did not look at those other measures. Because I think, yeah, this would be more authentic, I think. Of course, 25 samples - 25 subjects doing the Stroop task is also some kind of subsample from a population, right? So, as long as there are no crazy outliers, I was pretty happy with the results.
Oh yeah, of course. I just checked the histrograms. But it all looked pretty ok-ish.
Well, I - no. I mean, I don't really have the gut feeling or instinct at the moment to determine by eye if something looks genuine or not. But, I mean, the means and standard deviations looked similar to the real data set. So, I was happy with that.
So like I said, just one. I generated the data set of 121 and from that I sampled 25.
I used R.
Yes.
Yeah. Well, the data set I found online. I mean I don't know if it is real. They said it was real. I have no way of verifying that but I take their word for it, yeah.
Right. So, I only basically took the mean and standard deviation of the mean and standard deviation and used that for my random number generator to generate a new data set.
Not really. I am just very curious as to the methods that other people used. I mean, I was thinking about, maybe, I should use like an LCA model or an LBA model to generate data. And I thought: No, I am way overthinking it. It doesn't have to be that hard, I guess.
Not really. I mean I guess I underestimated it at first. But in the end it was not that difficult, I think, no. It is a pretty straightforward method, I guess.
I think so. I think, I mean, there are only so many things you can calculate from the template that you gave. So, the only thing I can think of is distribution of data, correlation between data and means and standard deviations. So, I am very interested in what the methods are for actually detecting fabricated data. Yeah, I couldn't think of anything else to keep in mind.
Yeah, because it is, I guess, fun to do something that is really not allowed in science. And yeah, I mean, I think [REDACTED] also did it and was like that sounds like a good challenge. Wonder if I can beat [REDACTED] with generating data. So, yeah, it seemed like a fun challenge.
Yes, but not the exact method that I used. So, I knew that [REDACTED] also were interested in participating but I think we are too competitive to actually discuss our methods with each other.
No, definitely not, no.
No, I just walked you through my method. There is nothing more to say. If you have any questions, feel free to come back to me. I am willing to give you the R code that I used as well if you are interested.
No.
