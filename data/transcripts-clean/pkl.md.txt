No, I am [REDACTED].
I got my PhD in 2011, so that is 6 years ago.
Social psychology is my field of origin but I do [REDACTED] in, so also cognitive kind of things. So, social cognition, the field.
Any experiments that include a Stroop task? No, not a literal Stroop task. But a lot of similar experiments. 
So, I know the Stroop task just from being one of the strongest effects and replicable effects in the cognitive literature. So, I know how it works, how it is supposed to work, I have never actually - I have programmed Stroop tasks but also for fun but also for assignments that I give out to students. So, I teach programming of experiments and data analysis, and so I understand the Stroop task quite well.
Yes, yes.
For me, that would be R and Python.
Relative to my peers in my own field?
Ok. Then I would say it is relatively good. So, I would say 8.
I would say a 7.
No, one day.
I wrote the script and that took about 20 minutes. And then actually fabricating the data - because it is simulated data - took 1 second.
I would say - 1 to 7? I would say 2.
Well, as I am sure we will talk about in a few minutes when we talk about the way I fabricated I used a drift diffusion model and I knew about this model beforehand, but that is because I read a lot about that model for analyses and now I used it in a generative way. So, it was not preparation for this specific research, but there is a lot of knowledge in there that I had that you don't have immediately if you just - So you need to be involved in those modelling procedures before you can actually use them to simulate data.
With modelling data? 
I teach it. And I - so, I teach R and I teach modelling with R and I would love to use it more for my own research.
I know of several – [REDACTED], and those refer to a lot of way of detecting things - so I know about like p-curving, but I am not sure you can - that is something you can detect - that is not something you will detect in a single data set, but I understand things like granularity testing which is something you won't be able to detect in here as well. I followed the whole, all the reports of Uri Simonsohn, all these other people who are trying to detect whether there is fake data in play or not. The stuff on Jens Foerster, on Diederik Stapel, I have read all about that stuff, yeah.
So, some of them is about things being - the most general method - most general description, I guess, would be to show that some attributes of the findings, some statistical attributes, is very unlikely under the assumption of random sampling. That is usually, I guess, what they are looking for. And that can be any attribute where it is - and another way is seeing whether the actual combination of data or the data points are actually plausible data points given the setup or design of the study. These would be the general approaches, I think, that people take. And I have seen people take different - look at different attributes of statistical -  or of data for different kinds of papers or different kinds of data fabrication.
GRIM, for instance.
That is the one that does the granularity testing seeing whether the - given that there is some mean and you only have whole integer numbers that can – that could have been answered, then that means that some means are plausible, but some means are implausible, you cannot get them with any combination of whole numbers. So, then there is a problem. So, that is the GRIM test. That is one. And you want – you want one, right? Yeah, ok, good.
In this case, no, no.
All of them?
All of them?
Ok. So, I am familiar with the Jens Foerster case where the data seemed to be way too linear than you would expect to happen purely based on chance. Well, Diederik Stapel, I read the book about how he fabricated his data and [REDACTED]. What else? I know about – I have read about Marc Hauser’s - made some “mistakes” – I am quoting – using quotation marks – mistakes in the encoding or coding of video clips. What else? I think Smeesters, I have read about Smeesters stuff. It is mostly psychology or social psychology kind of people. I am reading now a lot about – I am not sure yet whether people are convinced yet that it is fraud, but about the Brian Wansink stuff who seems to have some weird approaches to beating (?) data into submissions. What else? …
Well, yeah, I think that these questions are very much related to people who actually tried to fake the data by hand. But given that I have just – I have used a model – generative model that we know that describes reaction times and accuracy of responses pretty well. So, for me, I did not take anything of this into account. I just made the assumption that if you can analyze reaction times and responses well – and that has been proven and validly with drift-diffusion modeling, then using it in a generative manner should also work given some parameters that it uses. And actually I think that this is a very interesting test because if this data set is detected as fake data, it means something for the validity of using drift-diffusion modelling of (?) modelling responses- latency data. So, it would actually be interesting to understand what it means for the method in itself if the data are detectable as fake.
No, no. I wouldn’t have said yes to this if I would have needed to really by hand – I don’t like doing data analyses by hand, I want to use scripts for that. So, I also want to fake data with scripts, I guess. I am too lazy.
No.
In general or in this specific?
Ok. So, I guess, we have already talked about the inclusion of impossible errors – or, sorry, of impossible mean values, given you know the granularity of the data that goes into the means. That is one thing. Another thing is, I guess, that – specifically with reaction times – you would expect it not to be normally distributed but to have a tail because people are – can go really slower, but they can’t really go a lot faster than some specific speed. I would think that looking at the data themselves I guess you can estimate how likely it is that you get the data distributed as they are assuming that these should be distributed a certain way. Also, one thing actually by the way that I thought in specifically here was not clear in the instruction is whether the way the data are analyzed is including or not including the trials on which people make mistakes. So, I assumed that you just want all the trials but if you would also look at the raw data – now this is not really the raw data because you only get the response means of the participants – but I could have provided you with the raw data because this is what drift-diffusion models give you. So, for each trial instead of just the mean for each block, I could give the data for each trial that has been simulated and then you know, there you would even have more options to see whether the data are fake or not, because it will allow you to test all kinds of like impossible combinations of speed-accuracy-tradeoff, I guess, whether participants too similar in how they respond. But basically more in general, I think, it is all about whether the values are plausible given some assumptions about the world (?) – about randomness. And I think that the problem more generally about faking data is that humans are not good at generating random variables cognitively, so I guess that when people try to fake by hand, they copy-and-paste or they change some values but don’t take into account how this changes the distribution or the likelihood of the data. And I guess most of the people who do that kind of fraud fake that data in that way. They are just not knowledgeable enough to actually know what are the features of fake data or what changes that make their data unlikely where a data detective might look at those things.
Is this – am I still answering the question?
I didn’t have much sleep tonight, so …
So, more genuine would be in general when the combinations of data or features of the data are not unlikely given that the assumption that these are normally distributed variables, for instance. So, in the extreme example, if something has – like for instance, let’s say we are assuming that people make speed-accuracy tradeoffs. Then, showing a Stroop data set where people are both slow and make a lot of mistakes would be very implausible, not from a statistical point of view, but from a theoretical point of view. So that is one reason why something might be more or less genuine. So when it adheres to all this theoretical knowledge about how the Stroop task is performed, that would be one way to make data more plausible. The other way would be that - so this may be a point where it becomes repetitive, but would be where each value is possible given the granularity of the input and where the distributions follow the distributions that you would expect given a random process or in this case a process that would give you like a long tail in the distribution for the reaction times. These kind of things.
I took them into account by choosing to use a drift-diffusion model in order to simulate the data. But I didn't then also check, I just did one run of the model and used that whatever it was instead of , you know, running the model until I thought it looked plausible, which would have been another approach. But if I would have done that, then I guess that one way to - now that I think of it - would be like if by accident now I end up with a data set where the effect size is implausibly big, for instance. That would be a potential problem. 
Well, I guess that the drift-diffusion model takes into account just more generally all kinds of assumptions about reaction times and response and how they relate to each other. And that is a fairly complex story about the model itself, but it is basically the model using something called Brownian motion which is a concept from physics where - Brownian motion is basically you have some kind of particle, and then you have even smaller particles that you can't see, they are really order of magnitude smaller, they all hit from random directions, because we can't explain where they are coming from, but they hit the bigger particle from random directions. So what you see is the particle will move around what looks like random ways - and this is called the drunken man's walk, right - and now, this concept has been used in drift-diffusion modelling by simulating lots of data based on several parameters that have to do with how fast a response accumulates given some input and given some signal in the data. It models how fast it accumulates to surpass some criterion to say one or the other response. And this takes into account the way that the cognitive process might work in order to get to the answer of yes or no over time or in this case of a specific color, of naming a color. And I have used a very basic model here, the number of parameters that determine what this path looks like can differ from task to task and several tasks are modeled more - better with complex drift-diffusion models where there are lots of parameters and I chose a basic one based on the assumption that the Stroop is a pretty basic effect where there is not much - you know it is a very straightforward cognitive process. For me, that was the idea. So, that is why I used a basic model, which I am not sure whether that is correct thing to do or not. But that, I guess, is the kind of things that I took into account while simulating or faking the data.
It is easiest if I show you the script, right. I can give you the script if you want.
Let me see. It is actually pretty straightforward. Ok, so, here, if you give me your USB stick later on you can see it. But here, this is the whole script. So, here we have the 25 participants, here we have the number of trials, here is a function to simulate a single trial where you have as parameters the strength of the signal, a constant that is added to the drift, it is like a bias whether some people are, you know, biased to say one color or the other in this case. This is another bias parameter, the starting point, then there is the noise is (?) how much of variance accumalates per unit of time, and there are some other parameters, here bound, small time steps, it's the granularity of, you know, how much if you make the time more granular, so if there is a higher resolution of time, there is more randomness added to it. And then there are some other like fuzz (?), response time fuzz (?), I don't know (?) the number of steps, it is not even - there are not even that many parameters actually. And then this is actually doing the work here, this is the full simulation of one single trial. Here, you see some extra - oh, yeah, this is from an old script - this is not informational. So, I used this drift-diffusion model to create fake data to simulate data for students to then practice their analysis skills on. And then because of using this model technique I can, you know, choose the way I want, what type of data do I want to produce, do I want a small or large effect, do I want an interaction or not or anything like it is very easy to do that when you - and then you can look for special cases where you find specific outliers or whatever and you want people to train on that. So, potentially, being versatile in modelling and in R also makes you a very dangerous data faker, I guess. But people just have to trust me. But here you can have the full script if you want to. And I can actually run it for you if you want. So here we have simulated a data where we have a t-value - so this is a very strong effect now. And this is the congruent, these are the incongruent reaction times and, well, you can do so. Like here, I can just go on simulating data sets. I have simulated ten now.
It would possibly, but in this script I didn't do anything with that. So, actually, every subject is now treated - actually, these data are treated as just one single giant subject doing 60 times 25 trials and then I just, you know, took subsets from that to create single subject data. So in this case, there are correlations between subjects to the extent and within subjects to the extent that there are - let me see, am I correct in the way that I am saying this, I did this a month ago when you guys asked me to do this - yeah, it is correct what I am saying. So, basically, there is - I didn't take into account any correlations within subjects or between subjects that there should be.
No criteria. So, my feel - so, my assumption was given that it is produced by this drift-diffusion model which - that it should be better than I can myself fabricate. But I realized now that we are talking that perhaps like the difference signal strengths or the different parameters that I chose might show up as being implausible for a typical Stroop data set. I don't know that. And given that maybe I have not simulated it in terms of enough complexity including you know correlations within and between subjects, maybe that is something that will show up. I don't know. We will see. Do we get to hear that actually as participants how high you ranked in ...?
Ok, good.
No.
Well, I wouldn't have done a lot of more than I did now given the time that I wanted to put in it, but perhaps the - one thing would be the correlations we just talked about, within-subjects correlations probably. I can actually check what happens here. So here with the correlation between congruent and incongruent in that case, let's see, yeah, but we want to ... yeah, we can check that at least at the mean level for this specific - this is not the simulation that I gave you, so this is just another iteration. Yeah, that would not be very plausible, I guess, if you have a negative correlation between congruent and incongruent reaction times. So, that would be something that I would have had looked at. Although you know who knows maybe if I run this again I don't know what actually happens in my simulated data set, because I didn't look at it. So, that is one thing that I would have needed to check. So, I am becoming less confident about not being found out. And then another thing that I think now that I might have not looked at is how actually - I didn't check at all whether the average and standard deviations are kind of representative of typical Stroop effects. I didn't check that either. But I guess that could be sampling error, right? Yeah.
No.
Yeah, actually I just explained it by saying we used a drift-diffusion model with - I used a drift-diffusion model with several assumptions on the parameters which are all actually pretty basic. In the end, the only thing that deviated from what you would do by default is I made the decision about how strong the signal would be given a congruent trial or an incongruent trial, these are these values actually here.
Yeah, so 2.6 and 2.0. 2.6 is the amount of signal that people see in the stimulus if (?) it is an incongruent trail. And 2.0 is the amount of signal they see in terms of congruent trial. That is actually the only thing that then - these are usually parameters that you are trying to model, but now I gave them as input and then based on that the model - the drift-diffusion can generate the data.
Because I have simulated more drift - more data with this drift-diffusion model. I knew already intuitively that this would give me a strong effect as I assumed the Stroop effect would be. Now, what I could have done is I could have played around with not necessarily with the difference between these numbers but with how high these numbers would be. And that would give me faster or slower reaction times. And I didn't do that.
Yeah, they follow from the model, yeah.
No, so I just hit run once and I used that. But I could have just keep on reiterating the whole simulation until there was one that I thought looked plausible. But I didn't want to put time in that.
No.
Well, I actually also didn't do that. I just made the - for me, it was really interesting to see what would happen if you have just one run with drift-diffusion models which should be generating plausible data - whether that indeed would follow to be plausible given your procedure to detect it. But I see something, when I look at this now, at this template file, is that because you asked about standard deviation, I hadn't pay much attention to it, but that for instance in the incongruent condition, the standard deviation are larger than in the congruent condition, and I think you would expect this. Also given how reaction times behave, because you cannot - because when you go more towards fast reaction times also the spread will truncate, because there is - on the left there is kind of a minimum speed that you need to have. And also I guess when a block gets difficult sometime you are fast, because it is still easy for you, easy trial, but sometimes it is a very difficult trial, so you get larger dispersion while with the congruent stuff you might get - you might - you get faster on every trial, because it is all easy for you. So, I - it is not something that I took into account while I was fabricating, but the model gave me that. So now, I think that actually looks kind of nice.
Just one.
Yeah, so R.
Yeah. This is doing that, yeah.
No.
No. Well, yeah, I mean, yeah, I got knowledge about the Stroop task, that it is a strong effect, so the parameters that I chose were inspired by that it is supposed to show a strong effect.
No, yeah, I didn't pay attention to that. I should have actually to have a better chance at winning this game, but I didn't. 
No, except for the fact maybe that I should also give attribution that parts of this stuff, like this drift-diffusion-model [?] is just available on the internet and I used a lots of default stuff from there.
No.
Yeah, for sure, for sure, yeah. Although not as difficult as it would be when I do it manually, right. I would not know whether to start actually. Because if I would do it manually I would probably already have in terms of being able to detect it I would already probably make so many mistakes that it would be detectable compared to - I would - you know, the more knowledge you have about statistics, I guess, the more you know what should go right in order to be plausibe. And if you - I think manually faking is only - you can only do that when you don't know a lot about statistics, otherwise you go crazy. So if you know a lot about statistics you can use this model, but then you know you ask questions about, yeah, well, but how plausible - how valid is this model? And that would become a PhD project in its own, right, because that means you are actually investigating the validity of the model, which would be a really interesting methodological project, but you know for this specific task I wouldn't put that much effort in it.
I thought, it would. I became a little bit less confident given that we found out that maybe I should have paid attention to a lot - some of the complexities of the Stroop task more. But I think generally that the approach of using a drift-diffusion model if you use the right parameters should be way less detectable than more straightforward techniques, for instance manual fabrication, yeah.
Well, yeah, that would repeat the answer to the earlier question. If you do things manually, there is just too much to keep into account and basically you will probably make mistakes on some dimensions that you were not aware of. And these models are supposed to generate plausible data. That is why they are used to explain reaction time data.
Well, one thing that I thought about beforehand is that maybe if the - because this is based on random number generators and true random number generators don't exist in computers, that maybe in some way it could be detected. And I think the way to detect it would be then if that is true, given that this is generated with a drift-diffusion model, if you can then use a drift-diffusion model to analyze it and explain 100 % of the variance, which should be possible given that it is first generated with it that it also comes up with it, if that happens then that is too good to be true, right. So then maybe you can draw conclusion that there is a high likelihood that it has been generated by a drift-diffusion model.
Maybe. I don't know, I have never tried this. I should actually do it.
I think it is important work to find out. I have - in the past couple of years, I got a very dark view of our field and I think it is a very good idea to be able to find out ways to quantify - well quantify is not a good - to well to detect fraud actually. And although I think that statistical methods will never be the only - it will never be the nail in the coffin, right, the final nail in the coffin - it is a good way to start looking at papers that are already published and see which one we should or should not trust or who we should further investigate. And I have seen too many people whom I have trusted already - or were big names in the field, I am nut sure whether you can see I trusted them, but who were big, big names in the field that turned out to have fabricated data. And one is already too many actually, but there are more than one. And this shows to me that we cannot rely on just that people say that they are trustworthy, right. So, I think it is a good way to start looking, but I also think it is very dangerous because it has to be - all these methods, these automatized methods of figuring out data fraud need to be validated well if you ever want to really use them to detect fraud. Because otherwise you could make, you know, type I errors and call someone guilty who is not guilty. And so that's why I thought it is important to contribute to this study, because the better it gets validated now, the better these tools are going to be when they are actually needed. That being said, I also thought there is an ethical dilemma here, because I also thought that maybe it could lower the bar for people who might have less of a [?] to actually fabricate data once they have done it once. And so for people who use drift-diffusion modeling or anything like I do, it is already so easy to fabricate data that the only thing holding you back from doing it is just because you think, well, I am a scientist, I care about the truth, right, but I also know how easy it could be. So, I can - and that for me trumps the ethics part that I think it needs to be found out. And I actually hope that this can be detected, but it is also problematic - and I hope that that is because I used implausible parameters, but it is also a problem for the - if I didn't use implausible parameters, then this is a problem for this specific method actually. Not necessarily for this method of faking data, but for this method of analyzing reaction time data that this model doesn't fit. So, I thought that was an additional reason for me to participate in this study to see what happens with this specific method when you try to detect it as faking data. So yeah, it is a little bit of an incoherent story maybe but ...
No, no? Ok.
Well, yeah, I told them that I would do that. Not participants in this study. They are not participants in this study.
Some of them offered thoughts on what a plausible Stroop data set would look like. But I said that I don't really care about this because I have this model that is going to do everything for me.
No.
No. I am going to give you the script and then you can see all the details in the script, right. There is a - it is all documented, so it is really open science. And no, no.
