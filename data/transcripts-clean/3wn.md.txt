Yeah, PhD Student. 
I would say Methods.
No.
Well, I only fabricated some data for the Stroop task and I heard of it before.
Yeah, my undergraduate, I would say, yeah.
No.
Only R.
Peers? So like psychology peers?
Wow, that is very difficult. If it is psychology, I would say 10. If it is like statistics, I would say maybe 3 or so.
10.
Yeah, three days.
In total, maybe 2 hours.
2.
Well, first I thought about how I gonna do it. And then I did it.
Yeah, maybe one third thinking and two thirds fabricating it.
No.
No.
Yeah, ok. So, I am assuming your methods ... So, the goal was basically to be undetected by your methods. Now, I am assuming that your methods are good. Which means that you can't detect like properly generated data, right? Because otherwise your methods are shit basically, right? So that is like where I am starting. And then, it is very easy because the Stroop effect is something that is actually there. It is one of the most replicated things out there. So, my strategy was to just do the Stroop task myself. And then just generate data like that. And the only requirement is that we get a significant effect. So, I just played the Stroop task for 25 times - at different times - and I just take that. And that's it. So, that was the whole reasoning. And then - I was thinking about this - how to generate this ideally. But then the best is just to actually create the data how it is supposed to be created because then if your methods are working you won't detect it as artificially because it is not. So, that's it.
No.
Yeah. So, I mean you have these things with like how often integers are - different integers are appearing, I think. And if things are fitting too well some well known distribution. For example, if I would generate it myself, I would use something which looks like a response time. And then if it fits the data - if it fits some model and it fits too well, then probably something is a little bit fishy. But who knows? And, so, if I would do it in a way that I would generate it from some distributions, I would like add all sorts of random stuff to kind of avoid this way of detecting it.
I think that is the same, I think.
No, that is not necessary because I did not generate the data in an artificial way.
No. 
Ok maybe. I wanna add one thing: So I was thinking of intra-individual differences: And I did it like at different times to make sure - when I like tired and not tired and stuff like that - to make sure that there is some variation. And there is lots of variation. So, it worked well, I would say.
Well, that was like the initial reasoning.
No because like however - whatever the dimensions are that - how [?] determine whether it is a true dataset or fabricated. Because I generated them in like a genuine way all of these dimensions have to kind of point in the direction that [?] that it is not fabricated, right? Because it is not fabricated. So, basically, I kind of sidepassed (?) all these problems by just generating the data how it is supposed to be generated.
No.
No.
Yeah. So, I went online to find a Stroop task which I could do in my browser. And I found one. And then I just played it 25 times for the 25 participants. Then, it was actually 60 trials required but then in this game it was only 40. So what I did is for each participant I calculated - or for each round of me, basically - I calculated the ratio of errors and then I scaled up from 40 to 60 trials. And then again - and the missing ones I sampled from the whole pool of all trials of all participants. And that is how I scaled it up from 40 to 60. Because that was the only thing where I was thinking maybe you can find something because maybe of some variance or something like that that if less variance within person if you have 60 trials compared to 40 trials. So, I scaled it up. And that is the only thing what I kind of changed in the data after generating them in a genuine way. Well, and then I just calculated for each participant the mean in the two conditions and the standard deviation. And that's it.
Yeah. So, that is - I basically calculated from the data. So that is answered.
No, I just did one go because I knew that I was generating something which is not fabricated. So, there was no need for that.
No, because I knew that the process is a genuine one. So, I didn't look at anything.
Exactly, yeah. 
Yeah. So, I used a script online to get the experiment. And then I paste them into Excel, I [?] to R [?] of the pre-processing. And calculated the means. Exported it again to Excel. And that's it.
No, because I generated properly by doing the task.
Well, in the sense that I created them in the experiment.
Yeah, exactly. All of them.
No.
Can you say that again?
Difficult task? I don't get this. What is the question?
Oh whether I think it was difficult?
No, I think it was very easy because you were asking to fabricate an effect which actually exists. It would have been much more difficult - and much more interesting, I think, for you - to give me the task to create an effect which is actually not there. Because then I couldn't do it that way.
Yeah. It is going to be impossible.
No but like by logic: If you detect it, your method is flawed.
Yeah, I thought it would be fun just to think about how to do it. And then I already read everything and then [?], now, I can do it as well.
Yeah, a couple of people. Like when you sent the email around, people were like talking about it.
Nonono.
No.
No, I think I told you exactly how I did it.
