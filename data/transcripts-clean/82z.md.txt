I am.
Yeah, so I am in developmental psychology.
Eh, no, never.
Well, I knew about the Stroop task, but I - well, I might have done one sort of funny internet thingy (?) setting but never in an experiment here at psychology.
Yeah.
Yeah, R.
Probably something like 8.
I think 6 or s... - yeah 6, I guess.
Alright.
I did it in one day.
I think maybe 4 or 5 hours.
Well, I would say 6, quite some effort.
Yes. So, should I elaborate how?
So, what I - so, I did not really have any knowledge of the Stroop task. So, I wanted to get some feel for data like the Stroop task. So, first, I went online and googled something like what's the Stroop task, can I do it online, find a site where I could play, checked my own reaction times, get a bit of a feel. And then I didn't feel that was really good enough. So, I thought, well, there is probably data online somewhere of the Stroop task. So, then I went to the Open Science Framework and I found a large data set with Stroop task data and I used that to get some feel for that kind of data you get.
So, many 2 hours or something. 2 to 3 hours, yeah.
Ehm, no.
Well, not really, but I did think about this. And I have heard - so I have heard the most obvious cases in which, well, data fraud is detected is because lack of variance between studies or yeah. So, I did consider that.
Sorry, can you repeat the question?
Yeah, yeah, yeah, for sure.
So, I looked at the distributions of this data and tried to fit distributions to the data to get a feel for that so that I could later use to simulate the data. I checked correlations between - yeah - the different measurements, so for instance between the mean reaction time and the standard deviation and stuff like that.
No, not really, I guess.
So, I think low variance probably and ... yeah, so, I wasn't really sure (?), I think it's - obviously if maybe effects are too large or maybe if there aren't correlations between for instance the mean reaction time and the standard deviation that are likely to be there in real data.
Well, I think, people - most people are like onerous (?) in estimating variance. If you ask them to draw a random sequence of heads or tails or something like that, typically variance is lower than you would observe in real data.
Yeah, so what I thought was if the correlation structure that is there in real data is preserved in the simulated data.
That was sort of my approach to the problem.
Well, yeah, I tried.
So, first - so, we had to simulate 4 measurements per person. So, the mean and standard deviation of the congruent trials and the mean and standard deviation of the incongruent trials. So first, I thought, well, there is probably correlations between the mean and the standard deviation. And then there is also probably correlations between the reaction times on the congruent trials and on the incongruent trials and also for the standard deviations. So, in this data set that I found on the Open Science Framework, I checked - I checked these correlations whether there were present and how large they were and - yeah, starting from there, I started to simulate data with that correlational structure.
So, for instance?
Yeah, yeah. So, I did. I checked for the structure for the difference scores and for the distribution of reaction times, which I knew to be mostly non-normal but more gamma(?)-distributed. So yeah, I did consider these properties.
Hm. Well, I just tried to reproduce the similar correlational structure that I saw in real data. And I thought that would make it look real.
Well, I thought, because they are dependent I used this dependency to simulate the data. So, I started off with the - I th... - yeah, what I did was I checked for the difference scores between the reaction times on the congruent and the incongruent trials. And then - so then I had one difference score for each participant. And then I also checked for difference scores for the standard deviations. And I saw that these difference scores were more or less normally distributed - and correlated. So, large differences in reaction times also meant large differences in standard deviations. So, I thought I (?) should incorporate that. So, that was sort of my starting point. And then I simulated from two correlated normal distributions and I saw (?) like mean differences between these reaction times were something like 50, 60 milliseconds. And I think for the standard deviations something similar. So, I simulated data with those means and large variances. I think something like - I don't know - standard deviations of 100 to 200 milliseconds. And I correlated - or I simulated correlated data so then I had the difference score data and then I simulated using gamma distributions reaction time data and standard deviation data on the congruent trials and then I added the difference scores that I simulated earlier for the - to come up with the incongruent trial measures. Yeah, so that's what I did.
Well, not now. But probably, in later hindsight, yes.
No, at the moment I can't think of anything.
No.
Yeah, well, I think I just elaborated on that. So, I started with - I started from the difference scores - and I started by simulating difference scores. And then I used those scores to simulate the means of the data.
Yeah, so that was similar. So, I looked at the data I had of the Stroop task. And I - I checked these difference scores so it was approximately normal. So, I simulated a normal distribution of these difference scores. And then from a gamma distribution, I added - I simulated 25 observations and added the difference for the incongruent trials.
Well, not really. I think I did like fabricate the data multiple times to check like - more or less eyeballing the data - if the correlational structure that I observed in real data was found in the simulated data. And then I don't know maybe after 10 or 15 times - obviously it is a simulation so it comes out different but sort of similar every time - so then I thought, well, that is ok. And then I just copy-pasted the data I had then into the Excel file and it gave me a p-value that supported it so I thought ok, that is ok.
Well, I didn't really - I couldn't really think of anything else to make it better or more real. So, I decided it was enough.
No, not really. Yeah, I am not really sure. Probably, [?] I saw it and I was like this is reasonable or ... but not really like - I didn't go through a - how do you say it - thorough process of like simulating many, keeping them and then using some of sort selection criteria to determine which one would be the best or most real data set. Just ..
Yeah.
Yeah.
Exactly.
Yeah, well, I did. So, this is a point. Because of the method I used I somehow sometimes ended up with negative standard deviations which is a bit odd. So then I just some of sort of last (?) trick just to put that - always be a positive number.
No, well, I just set it to the absolute value. So, I just checked if it is negative and (?) set to the absolute value.
I think I did, ja. And then I started wondering how can you ever tell from these 25 data points if they are derived from a gamma distribution or from a normal distribution or ... yeah.
No. I did plot histograms of the data and I checked for negative values.
I think maybe 15, 20.
Yes, so I used R.
Yeah, I think so. So, I used the R random number functions of the - I think the rgamma and the rnorm functions to simulate the data.
I used only real data to - not to fabricate the data but only to get a feel for the kind of distributions these data have, yeah
Yeah, exactly.
No, more to just get a feeling. So I think what I did was - yeah, it was a large data set so I just looked at the distributions to see what it was. And then I draw like samples of 25 observations from that - from that data a couple of times to get a sort of feel how 25 data points would look like.
No, I think I kind of told everything of how I fabricated the data.
Not really, no. So, I have a lot - well, I don't know if I have a lot but I have some experience in simulating data. And if - yeah sort of fabricating data. And I use it in my work to get some estimates of power or to get a feel of what my actual data would look like - to, well, plan analyses in advance and stuff like that. So, it is a common task for me to do.
Well, I am a bit uncertain about that. So, I know I wouldn't spot it as fabricated data but I am not aware of any detection methods or anything other (?). So, it is kind of hard to get a feel for that, yeah.
Yeah, so these sort of things that I took in consideration when simulating the data. So, I thought how would I try to detect if data is fabricated or not. And then, well, the sort of obvious things are then that there is low variances or weird scores are not in the data or there is no correlation between dependent measures that you would expect or - yeah, so I tried to incorporate that as much as possible.
Well, I thought it is fun. So, I think it is important to get a bit of a feeling for - if you can detect these things if it is real data or fabricated data and, well, for the reasons to prevent fraud and etc. etc. But I also think it is important to - or I think it can be very useful to fabricate data for the reasons I just mentioned to get some power estimates, to plan your analysis ahead and stuff like that, yeah.
I only mentioned it with my supervisor who also wanted to participate but he didn't have the time - or he was too late, I don't know.
So ...
Nonono, not at all. I did it all by myself.
No, not really.
No, I think I told you everything of how I did it. So, yeah.
