No, I am not. I am a junior researcher. So, I don't have a PhD yet, but I am also not in a track to get one.
Social psychology.
Not a Stroop task. I conducted interviews, [REDACTED], and one experimental - one experiment, so in the lab. Do you need to know more about that?
Oh yeah, ok. So I don't have any experience with the Stroop task other than that I know what it is and those (?) and I have been a participant in it, but I didn't use it for my own research.
Exactly, yes.
Yeah, in the past or I think I read about it in a lot of papers when I was a student. And also for this research, I read some papers about it to be able to fabricate data that is naturally for the Stroop task.
Yeah, just SPSS.
Ok and with peers you mean fellow researchers?
Ok, so I'd say 7.
5.
I spread it over several days. I did some things - part of it I did two weeks ago and then another part two days ago.
Like total days or ...?
I think I did something with it on three different days.
I think 8 hours.
6.
I prepared by searching for previous research on the Stroop task and, yeah, I mean this was part of fabricating it, I wrote down the means of - and standard deviations of these previous researchers for a lot of them. So, I searched 14 different papers with 14 different means and I read a lot more papers, but a lot of those papers had special conditions with the Stroop task, for example anxiety disorders or schizophrenia or something. So, I didn't use those. So, that was a lot of preparation, I feel.
3 hours.
No.
No. I actually haven't even thought of doing that. That would have been good preparation.
Yeah, not very extensively, but I thought - I just thought about how natural data would look, that there would be some outliers, for example, that it wouldn't be perfect or maybe too significant or too predictable. So, I thought about that and tried to remind that all the time when I fabricated the data.
Yeah, I think so because I reminded myself of it.
No, I think I did all the means I filled in on a different day than I did the standard deviations.
Yeah, I think it would look fabricated if it is all too neat and too like wishful thinking or too perfect - if it looks too perfect, then I think it would be suspicious. If there are no cases that go against what you predict, so are (?) maybe the other way around, then I would think maybe that is suspicious, but it could also be the case. So an example - especially with the Stroop task what is very reliable, because it has been replicated so much, I thought it was very difficult to decide how many outliers or weird things I should put in there. And I thought, maybe if you have a lot of - maybe people have a preference for certain numbers when they write it down or try to avoid double numbers or numbers like 100 or 200, because they think, no that is too obvious, but in a real world situation the chances are very likely that a number like that would be there. So, I also tried to correct for that by sometimes putting like 117 or something or even 200, I think, is in the - something like that.
Yeah, so if there are some mistakes and some things that a researcher wouldn't be happy about, some things that you don't want in your data. If those things are present, then I think that will look more genuine.
Yes.
When I wrote everything down, I tried to correct myself by looking at how many times I had the same end number and starting number and I put in on purpose some outliers and some, yeah, numbers that maybe some other people would try to avoid like 400 or something.
What do you mean?
Oh yeah, so after I did all the means, I calculated myself in SPSS what the standard deviation was of these means and if that was corresponding to the standard deviation that could you expect from a Stroop task and I corrected for it. And also I looked at the spreading just in Excel, in a different Excel sheet, I tried to see if all the numbers were on a linear distribution and it wasn't, so I was glad I checked that. So, I also corrected for that.
What criteria you would check it on, you mean?
Yeah, so the approximately linear spreading, but not too linear. And that at least the mean and the standard deviation overall were very much similar to the means and the standard deviations I have seen in previous research. So, at least I know that those are realistic, that was the most important thing that I tried to keep track off that outcome - so if my fabricated data were in correspondence with realistic data.
Yes, so I used - I think I used a standard deviation to calculate the spreading of the means. Of course, I did and that's why I checked it after I did the means in SPSS to see if the standard deviation was alright, so I am very confident because of that that my means have a realistic spreading, but for the standard deviations I thought it was very difficult, because it was really hard to find in the literature standard deviations of individual cases, so that was - and I really had to dive into statistics again to see how individual standard deviations deviate from the overall standard deviation. And in the end, I was able to find some data from google from individual cases that I used to find a mean individual standard deviation and from that mean individual standard deviation I created all the other individual standard deviations and here I tried to correct myself where my - wanting to put random numbers in by just going to a website like it was called randomnumbergenerator.org and I asked it to generate 30 - because I thought there were 30 cases, but there were 25 at the time I did this - 30 random numbers between 150 and 250 and then I just use those for the congruent condition. So, the first 25 of those random numbers I used for the congruent condition and then from there on I noticed that usually in the incongruent condition standard deviations were a little bit higher, so then I adjusted it myself that some of those standard deviations were somewhat higher, but some also somewhat lower. So here I also created some outliers and some difference between the numbers and that was random in my head, but probably there is not completely random, so I might go wrong there.
Yeah, so when you mentioned that I could have - when you asked if I researched data detection articles, I think I could have paid more attention to those and tried to find out how you were going to do the detection instead of just thinking about the things I can come up with.
No, I don't think so.
Yeah, I think some of this I already said, but it might be good to repeat it. So at first, I looked at other studies and wrote down the 12 or 13 means of other studies. And then I used those means and I - then I just came up with new means for myself that were around those means. And then I did - I calculated the standard deviation in SPSS to see if that standard deviation was corresponding to a realistic one. And then I adjusted the means again and again until it was realistic standard deviation or the one I decided for myself that I wanted it to be. And then I looked at all the means again and I tried to put the means in random case rows so it wasn't sanding (?) all. And then I think I adjusted some numbers again and again and again and hoping that it would be sort of random, which obviously probably is not. But, yeah, I did it like that.
Yeah, so at first, I didn't know about individual standard deviations, so I inserted wrong ones. And then when I looked at it another day, I thought, no, this cannot be right, so I googled for Stroop with a Excel S between brackets so I would get Excel sheets with data hopefully or I tried like a 1000 different google searches, but this one in the end was one that really got me data. So, but most of those data sheets didn't include individual cases, only one. So, I used that one and I had to put them all in SPSS and calculate the standard deviations, because those were standard deviations even per trial. So, I had to first calculate the standard deviation for a set of trials. This was the part where I really don't know if I did it right or not. But I thought that in the end, the standard deviations were somewhere between 150 and 250, but there were a lot of outliers on reaction time in that file which was very difficult because in the instructions of the study it wasn't said if we could remove outliers or not. And in most studies where they do the Stroop task they remove outliers over 2000 milliseconds or they even already present people with a new one. So, I didn't know from your instructions what the Stroop task would exactly be performed like -if participants would be presented with a new word after 2000 milliseconds or not. So, I just decided for myself to remove the outliers for from above 2000 milliseconds. And then I found the standard deviations were between 150 and 250 on average. So, that's when I used the random number generator to generate random standard deviations for the congruent condition. And then from there, I did myself somewhat random numbers for the incongruent condition, where I made sure that most of the time the standard deviations in the incongruent condition were higher than in the congruent condition. 
Yeah, I did it almost separate. But when I allocated the standard deviations to the cases, I looked at the means so that I gave low means a lower standard deviation than really high means, because when the means are higher then there is probably an outlier and an outlier has a really big effect on the standard deviation. So I then - those higher means I gave a higher standard deviation. But also sometimes I turned this around, because some people are just slower, so they can have a high mean but a low standard deviation, because they are quite accurate, but just slow. So, yeah, I didn't really know how to handle that, but I tried to look at that.
Yeah, I twitched (?) it a lot until I thought, yeah, now it looks good or now I am happy with the spreading and with the mean and with the SPSS statistics.
Yeah so with SPSS and the Excel I tried to see if I - if those things were ok and then if necessary, adjusted and re-check it.
I checked the standard deviation of the means. I used SPSS to find standard deviations of the data I found online, so from there I didn't do any checks anymore, because I wouldn't even know how to do that. And I checked the spreading of all values in a - just a scatterplot to see if they were linear.
Yeah, but just with - just how I perceive it and the plots.
Yeah, but with the same measures (?).
What do you mean exactly?
25, oh, if I did more than 25?
Yeah, I immediately put in 25 from - in the Excel sheet and I worked actually constantly in the Excel sheet changing the means when I thought that it was necessary.
So, probably every mean was changed twice or three times.
The standard deviations were four times changed, I think.
SPSS and, yeah, Excel in a different sheet.
Yeah.
Yeah, yeah.
Yes. So, the data I found online from the standard deviations that were really individual cases and the data from 14 previous studies.
I used it as an inspiration mostly, but I think I chose three means that I thought were very reliable because the studies had a really big n. So, I used those three means and those - from the congruent and incongruent condition as a standard to do the other 22.
I probably adjusted one number, so instead of 679 I did 678 or something.
No, I just - when I look at my notes now, I see that I also before - actually the first step I took was doing an online test myself and write down my own personal score on the Stroop test - task.
Yeah, I was very slow. I was very slow in comparison but I did see the difference between congruent and incongruent, so it still gave me a little bit more feeling with the task.
Yeah, it was more difficult than I expected. The means I didn't think were so difficult but the standard deviations were really difficult, I think.
That I really had to dive into statistics and how it actually outworked to come up with realistic numbers. And even though I used real data as an inspiration, I am still not sure if the spreading of the standard deviations is right. So, like the standard deviation of the standard deviation. I do not know if I did that correctly.
No, I think probably you will figure it out.
I don't really have a hunch. I just think there is a lot more than I came up with just by myself and probably you have a real - a good program thing with different algorithms that maybe my test is even too significant or something, that was something I found hard to decide because yeah that is difficult. So, I don't know, maybe my data is too significant and I don't know what exactly, but I am pretty sure there are things that I haven't thought of, that will come up.
Because I think it is very important that people don't come in the temptation to fabricate data. Because I usually don't like it that people don't take social science seriously and it hurts me as a part of the group social scientists that sometimes there are some bad apples and then you know the other scientific fields think of us psychologists as not to be taken serious or fraudulent, which I think is very bad. So, if I can help in any way to prevent that further, then yeah ... And of course because I get monetary compensation.
I discussed it with my colleagues, but not the content of my work so I didn't discuss with them how I should do it, but just that this study was there.
No, no.
No.
I am just looking through my notes, but I think we have discussed everything about it, so yeah.
