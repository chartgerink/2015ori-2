### Legend

1. [REDACTED] means that the original word/fragment was deleted to ensure the anonymity of the participants.

2. [?] is a placeholder for words/fragments that could not be transcribed.

3. (?) means that the transcriber was not completely sure what the last word/fragment was, but had a guess.

4. Sentences that begin with "I:" were said by the interviewer

5. Sentences that begin with "P:" were said by the participat


#### Note

This interview was conducted in a cafe (with other guests sitting in some distance to the interviewer and the interviewee).


### Block 1: General Information

I: So, now we will start with the first block. The goal of this block is to get some general information about you. So, the first question is: Are you a PhD Student?

P: Yes.

I: And what is your field within psychology? With field, we mean for instance social psychology, cognitive psychology etc.? 

P: Well, my field is about psychology of language. It's a type of interdisciplinary field which could fit into both cognitive psychology and experimental psychology.

I: Ok. And did you conduct any experiments including a Stroop task in your career so far?

P: No because Stroop task has nothing to do with language things.

I: Ok. But could you describe your knowledge or your experience with the Stroop task a bit?

P: Yeah. Well, actually, I knew what the type of the task was because when I was doing some practice with E-Prime software, one of say the exercises put (?) in E-Prime [?] was to design a type of Stroop task. So, I was fully aware of what the task is like and the underlying theories behind that task. Yeah, I mean, it was not the first time that I heard about the Stroop task. I was familiar with it although it has nothing to do with language.

I: Ok. And did you ever analyze data of a Stroop task experiment before?

P: Not a Stroop task. But data out of reaction time studies, yes. But also it is also a type of reaction time study. But, yeah, I have done many analyses with (?) reaction time studies.

I: Ok. And which statistical analysis programs do you use at least once a week? Multiple answers are possible. For instance, SPSS, R, Stata, SAS, Matlab, Python, or any other program? 

P: It is (?) SPSS.

I: Ok. And how would you rate your knowledge of statistics relative to your peers on a scale from 1, extremely poor, to 10, excellent?

P: Well, actually, I suppose there is nothing about SPSS that I cannot [?]. I mean I am fully aware with all the statistical analyses which it can be done via SPSS. And also further than that, when it is - what's it - the post-analysis (?) and SEM.

I: Ok. But so like if it comes to rating your knowledge of statistics, like if you compare yourself to other researchers or scientists in your field, how would you rate your knowledge of statistics on a scale from 1, extremely poor, to 10, excellent?

P: But like - 10. Because I can run SPSS very well and all the statistical analyses there are fine with me.

I: Ok. And how confident are you that your fabricated data will go undetected as fabricated? Again on a scale from 1 to 10, where 1 means extremely insecure and 10 means extremely confident. 

P: Well, I think as a fabricated data, I think it could be a bit challenging for someone who is - who looks at it as a real data to understand that it is fabricated.

I: Ok. And like if you would rate it on the scale from 1 to 10, which number would you give?

P: Well, I suppose, I will give it number 9. Yeah. 

I: Ok, then this is ...

P: And I will put 1 a score for any expert who does might have an idea in what [?] it could be detected that it is not a real data - set of data.


### Block 2: Timeline of Data Fabrication Process (When?)

I: Ok. Then this is is the end of the first block about general information. Now, we will start with the second block. The goal of this block is to get some information about the timeline of the data fabrication process. So, did you fabricate the data in one day or spread the data fabrication over several days?

P: No, I did it in whole day. But I did not just leave my computer. I mean, I was just stuck (?) to it for a whole day until - from the time I started inserting (?) the data from the time the data was inserted (?) into that Excel file it took a whole day.

I: Ok, so ...

P: If you want to know in how many settings, in one setting.

I: Ok. And how much time in the sense of how many hours do you estimate that it took you to fabricate the data in their entirety? 

P: Well, the pure defined (?) time? I mean, if I exclude everything that I just was doing in the middle - say having a coffee or ... - I think, something between 7 to 8 hours.

I: Ok, thank you. Let me just check - yeah, still running, ok. And how much effort do you feel you invested in fabricating the data on a scale from 1 (no effort at all) to 7 (a lot of effort)? 

P: Well, how do you mean by effort? If it is just thinking about how it could be manipulated so that in a way it cannot be detected - if you put - if you translate that effort into mental, I mean, into thinking process, well, that means that I would put the highest degree of that effort. But if you mean how much difficult it was for you to think about it that it could be manipulated, well, it was not that much challenging.

I: Ok, but so like yeah, in terms of like how hard you tried you would give the highest score possible?

P: Well, this question is a bit tricky because it could point to two different things. In terms of, I mean, the thought process, I was fully concentrated on that. I mean, whole my thinking was devoted to the way it could be manipulated. But at the same time, if you ask me, was that a challenging thing to do, I would say not. It was not challenging, but I had - this is [?] just took whole my thinking - I mean concentration - because I just did my best to fabricate it in a way that it might seem genuine. It was a, I mean, deep thought process, but at the same time not very much challenging.

I: Ok. And did you prepare in any way before starting to fabricate the data?

P: No. What type of preperation do you mean?

I: So, for instance, did you read literature on detecting data fabrication?

P: No, I did it just on my experience out of SPSS because I have done many analyses by SPSS. 

I: Ok.

P: Yeah, I just relied on my own experience and how it could be manipulated in a way that it might look genuine.

I: Ok. Or did you look into previous cases of data fabrication and how they had been detected? 

P: No, I did not. I just fully relied on my own experience on what real data set can look like. And then based on that I manipulated. Because - well, actually, to begin with I didn't - I used a real set of data set for one person out of a reaction time study in which I knew that it had two conditions - like congruent and incongruent. Another (?) study of my own - one section of it also had two conditions in which the difference between two conditions were statistically significant. I used the data for - I mean, for one of the participants from my own study, put it into the software, and then tried to play around it. I mean, for that particular subject that I got from my data base it - as I said it had two conditions like that congruent and incongruent and I knew that it is going to be statistically different between these two conditions. So, the way I played around it for the imaginary 25 participants was to play around that - I mean, real one sample of data so that the type of difference between those two conditions are kept with some fluctuations - ups and downs - but the same or I thought I did it in the same way, the same type of fluctuation has been put in the second condition so that the real essence is kept there, I mean, that statistical significance is kept there and it is not damaged.

I: Ok. And did you also consider other approaches to fabricating the data?

P: How do you mean by other approaches?

I: Like so I think you could fabricate data in various ways. So like did you think about other ways to do it or not?

P: No, I just tried to stick to that real, one sample real set of data from one sample which was genuine and I looked into it the way - the fluctuations - I mean around that, ups and downs, might seem genuine and at the same time kept in both conditions.

I: Ok, thank you. Then this is the end of the second block. Do you have any other comments about the timeline of the data fabrication process that you think could be interesting for us to know? 

P: The timeline? You mean how much it took for me to do it?

I: Yeah, and like ... what you ...?

P: Because I said it is about 7 to 8 hours.


### Block 3: Broad Framework of Data Fabrication Process (What?)

I: Yes, ok. Then, we will now start with the third block. The goal of this block is to get some information about the broad framework of the data fabrication process. So, could you name specific characteristics that would make data look fabricated or more fabricated in your opinion?

P: Oh, sorry I just lost my track. Could you please repeat your question again?

I: Yeah, of course. Could you name specific characteristics that would make data look fabricated or more fabricated in your opinion?

P: What characteristics might lead you to detect that a set of data is fabricated .... well, sometimes it was very much interesting to me - when I was doing on that fluctuations I just found that in some period of time the type of the numbers I was entering into the system was [?] pretty much repetitive. And the very time that I detected it that the numbers are going to play around the same thing, I just tried to - I mean - change the way my fingers were just playing with the keyboard. It was from up to down instead of - say buttom to up or from left to right so that more variety of the numbers are being kept there but the thing that I detected it myself when I wasn't aware of it when I looked at the data I thought the repetition of numbers. Numbers were much like each other and, yeah, I mean, for example, more in 6 or 7 rows consecutively I had lots of 8s, lots of 7s, lots of 6s.

I: Yeah, ok. And could you name specific characteristics that would make data look more genuine in your opinion?

P: That is the very thing that I have used. I used a real set of data from one sample that the data, I mean, was genuine and it had two conditions, and I knew beforehand that the data was, I mean - of course, it is not meaningful when there is only one subject and to make a comparison between two conditions, if, I mean, these two are statistically significant because after one it is not meaningul statistically to run an analysis but it is within an, I mean, it could just example within a sample in which the two conditions were statistically significant. That's how I based that fabrication - based on the real data of that one sample.

I: Ok.

P: That means that - I just modeled this fabrication based on one sample of real data.

I: Ok. But if it comes to real data, do you know some certain characteristics that like real data always has?

P: Pardon me.

I: Like, so could you name specific characteristics or features of real data like criteria how you would determine whether a data set is real or not?

P: Well, for example, [?], I mean ... what is it in English - let me think ... dispersion, yeah, I mean, the way data is dispersed, and I mean that standard deviation. And then - yeah, these are the things that could hint about the data is a good one or not. Of course, it - I had different several sets of data about - it is very difficult - I think it is very difficult to detect if someone has done it very much carefully. Otherwise, the person is really a statistician. But if someone has done it carefully, I think it is very difficult to find out.

I: Ok. And did you take these characteristics you just mentioned into account when fabricating the data?

P: Yeah because the way I did that fluctuations was in a way that, for example, the output is not going to be the same for two participants because it was ... I mean the probability of having exactly two outputs for two or three subjects is very much, I mean, low. The possibility is very much low. The way I did that fluctuation I was very much - I mean - careful about doing in a way that the mean and standard deviation out of, for example, these imaginary 25 participants for not 2 of the imaginary participants are going to be the same thing.

I: Ok. And did you take into consideration relations in the data other than the Stroop effect itself? 

P: ...

I: For instance the distribution of the scores or other aspects that could be inspected with the data set.

P: May (?) yes. Because, actually, you wanted it to be something meaningful, I mean, that could support that Stroop effect, yes? Yeah, I took it into consideration.

I: And how did you do that?

P: Again, by looking at a real set of data, how those dispersion is there, and running the analysis by SPSS to see how they might (?) look like each other.

I: Ok and what criteria did you use to determine whether you thought your fabricated data would go undetected? 

P: Yeah, I think I answered previously. I just based - made the comparison of the dispersion and yeah standard deviation and everything. Make comparative, I mean, looking into real set of data and then when (?) I fabricated it.

I: Ok. And did you have specific and different criteria for the means and standard deviations that you wanted to check?

P: How do you mean?

I: Like, so like to determine whether your fabricated data would go undetected as fabricated did you have sort of a checklist - things that you wanted to check once for the means and for the standard deviations?

P: For both, of course. Yeah, because - and it sometimes in the middle I just did the analysis with software to see how this time that standard deviation looks like, how the mean looks like.

I: And what did you look for then? Like how should they look like and how shouldn't they look like?

P: Well, as I said, I just based everything on a real set of data.

I: Ok, so, you compared the - your fabricated data set to the real data set ...

P: Yeah.

I: ... and tried ...

P: Tried to have everything out of it. If it is ok - because it was something done by me and I was fully aware of the whole process of it. For example, I had run the experiment with 86 participants and I also had another study run by participation of 24 participants. I just looked into the way they might just have some overlaps to look like a real set of data.

I: Ok. And so you mentioned that you checked for the standard deviations. Did you also check for other relationships in the data, for instance like the relationships between the means and standard deviations or the correlation within participants or so?

P: Well, actually, I mean that the standard deviation comes from the mean, doesn't it? It is very much related to that mean.

I: Yeah.

P: Because it shows how much, I mean, the unit that is dispersed from that mean. For example, plus 1, 2, 1, minus 1. They are all really related.

I: Ok. And you also checked for those relationships?

P: Yeah.

I: Ok. And in hindsight, are there things you think you should have paid specific attention to while fabricating the data? 

P: Well, it was also good to look online about the sets of fabricated data if I could find something on the net (?) and to see how they could be detected by a statistician, yeah.

I: Ok, then this is the end of the third block. Do you have any other comments about the broad framework of the data fabrication process that you think could be interesting for us to know?

P: Yeah, another thought for you: As I told you, the way I just set it based on a real set of data I tried to make the fluctuations really genuine as a real set of data. And the very - I mean, the [?] ability that could be detected with different participants in a real set of data but at the same time in a way that the differences between these two conditions are kept statistically significant.


### Block 4: Specific Steps of Data Fabrication Process (How?)

I: Ok. Then, we will now start with the fourth block. The goal of this block is to get some information about the specific steps of the data fabrication process. So, could you indicate what steps you took to fabricate the means for the participants?

P: Yeah, I said - for example, I had 24 participants, each one 60 trials, 30 in each condition, and when I was putting the data into SPSS, first I used a real set for, for example, participant number one and based on that real set for 60 trials I just copied and pasted into the whole 60 trials for the second one but with fluctuations that I was very much - I mean - concentrated on the way I am doing that fluctuations because sometimes in the middle I just [?] to the data to see how standard deviation and mean looked like.

I: Ok. So, you started from a real data set ...

P: Yeah.

I: ... and then you changed the values ...

P: Yeah, exactly.

I: Ok.

P: One sample from a real data set. For example, participant number one in here - the data from participant number one is the real data.

I: Ok. 

P: For both conditions. For condition - for example - congruent and incongruent and based on that I just played around it.

I: Ok. And so, did you do it on the participant level or on the trial level? So, you said that you had like 60 trials for each participant and then you like had values for each trial or for each participant?

P: I don't get you (?), I am sorry.

I: So like - so, we asked you to fabricate the means and standard deviations for 25 participants. But then like each participant had again 30 ...

P: 60 trials.

I: Yeah, right. And so did you fabricate the data for each trial or ...?

P: For each trial.

I: Ok.

P: Yes.

I: And then at the end you ...

P: Got (?) the mean.

I: Yeah.

P: Yeah, exactly.

I: And the standard deviations from the trials?

P: Yeah, exactly.

I: Ok. Yeah, so, like the next question would then be: Could you indicate what steps you took to fabricate the standard deviations for the participants? 

P: Yeah, yeah exactly.

I: Ok. And did you repeatedly fabricate data until you were satisfied with the results? 

P: Yes, yes exactly.

I: And how did you determine whether you were satisfied with the fabricated data or that they needed to be adjusted?

P: Well, actually, exactly I mentioned it. Just looking at the way the mean out of - I mean - the whole 60 trials for number 1, separately number 2, number 3, number 4 participant the way they look like a real set of data.

I: Ok and did you try to inspect whether the fabricated data looked weird? 

P: Yes, because I was very much cautious that - because of that repetition within (?) using the numbers that I - I just - I was not aware of it, I was doing it unconsciously, really. But I have no idea where is that - during, I mean, at that time I was inserting the data I just found that there are going to be some repetitions between the numbers, not necessarily the same number, but the same sets of number. For example, the frequency of 8, 9, 0, and 3 were being very much - I mean - more than the other sets of numbers and it was eye-catching.

I: Ok and then when you realized did you try to counteract and did you then even count the number of combinations that you had or was it more like a gut feeling or ..?

P: I just changed those combinations, kept - I mean that there was a fluctuation with another sets of numbers so that the variability in using different numbers - I mean and the numbers which I am referring to is in terms of 10 millisecond - you know what I mean.

I: Ok.

P: Because the range might be between 700 and 800, yeah, it doesn't show the variability but what I am pointing to is about even 1 millisecond or 10 millisecond - within 10 milliseconds. 

I: Ok. And did you try to inspect whether the fabricated data looked genuine?

P: Yeah because - Yeah, I just answered before.

I: Yeah, ok. And how many different mean-sd combinations did you fabricate before getting to the final fabricated dataset?

P: Well, I have no idea. Because, as I said, just in the middle of it, I just ran the analysis to see if it seems ok or not. But I have no idea how many times I did it. Because it was pretty repetitively done.

I: Ok.

P: I have no idea how many times. Perhaps 7 or 6.

I: Ok. And besides the supplied spreadsheet, did you use any other computer programs to fabricate data? 

P: SPSS.

I: Yeah, ok. And did you use a random number generator to simulate data during this study?

P: It is a good idea to do it. This is why (?) I just found out that there will be some repetitions in using the numbers. That is why I just detected in the way I was inserting the data myself. It was good but no, I just did it - the way [?] detected that there are going to be some similarities and some repetitions but I just tried to modulate to - I mean - to change it manually.

I: Ok, and yes, so the next question is: Did you use real data during the fabrication process?

P: Yeah, yeah.

I: Ok and so like ...?

P: Number 1 is - has the real data, yeah.

I: And the other ones were sort of inspired by that, right?

P: Yes, exactly.

I: Ok, then this is the end of the fourth block. Do you have any other comments about the specific steps of the data fabrication process that you think could be interesting for us to know? 

P: No, but actually, I just described the whole sections. The whole process is not something very much interesting. I mean when you fabricate the data you do not have a good feeling. I mean the whole process does not bring any interest. But the way that I have (?) tried to have variety of numbers - not I mean the way repetitions - those repetitions were very much eye catching even for me. And the way I just based it on a real - one sample dat - real data.
 
### Block 5: Underlying Rationale of Data Fabrication Process (Why?)

I: Ok. Then, we will now start with the fifth block. The goal of this block is to get some information about the underlying rationale of the data fabrication process. So, did you consider fabricating these data a difficult task to complete?

P: Eh, well actually, I spend about 7 or 8 hours. That (?) difficulty in terms of the duration, yes, because I was very tired at the end of it.

I: Yeah. But you thought like it is not a - like it takes a lot of time but it is not a very challenging task, you said earlier, I think.

P: I suppose, yes. Because at least the output to me seems good.

I: Ok. And do you think that your approach to data fabrication will be difficult to detect as fabricated?

P: I have no idea because this is the first time that I have fabricated a set of data. I know many things about SPSS but I do not know many things about detecting fabrication in data. So, to me, it seems good. But actually the one who is expert in detecting any type of data fabrication should have an opinion on that. Well, if you ask me, I say I am very well - I am very good in doing different statistical analyses with SPSS - very much complicated ones are fine with me. I can run SEM very easily. I can run many different things via SPSS. But this is my first time doing data fabrication. I have not - I have never done it before. So if you ask me, do you think this set of data is very much genuine, looks very much genuine, if you ask me I would say, yes, because the output I have tried to model it after a genuine set of data. But this question is what - and I would be very much happy if we could be informed about the way we have done. Do you think it would be possible to inform me that, for example - I mean, the very expert who specializes in detecting such things how much, say from numbers 1 to 10, has rated the degree of, I mean, the way it looks genuine. Do you think you would inform me of that?

I: Yeah, I can give you a contact form afterwards how you can ask your questions.

P: Yeah, because actually the very file that I gave you, it does not have any signification of my name - eh indication of my name - so how do you know which data set is mine?

I: Can we talk about this after the interview is over?

P: Ok, ja.

I: So, like do you have any guesses about how your data set could be detected as fabricated - any hunches about that?

P: No actually, because as I said I am not an expert in that.

I: Ok.

P: I have no idea what tricks are there. Really, I don't know.

I: Ok. And why did you decide to participate in this study? 

P: Perhaps to test myself, to test myself, and to understand ... and also to learn because later on I should also be able to understand the way data fabrication can go on. Well, it doesn't mean that for learning everything we always (?) have to go through with it but at least you should have some hunches about what that's look like. So, at least I should have done it once earlier myself to see how it works so that later on I could be able to understand if someone has done data fabrication or something.

I: Ok. And one question that I have is: How did you select the data set that you compared your fabricated data set with? Because you have said that you have conducted many studies on - or like reaction time studies ...

P: Yes, yes.

I: And how did you decide which data set you would use to compare?

P: Well, actually, the very second that I needed to have a data set at least with two conditions and which the statistical significance between two conditions is meaningful.

I: Ok. And did you discuss this study or the fabrication of the dataset for this study with other people?

P: No, never.

I: Ok. So you had no help in fabricating the data?

P: No, no.

I: Ok. Then this is the end of the fifth block. Do you have any other comments about the underlying rationale of the data fabrication study that you think could be interesting for us to know?

P: [?]

I: Yeah like whether you have with regards to the questions that I asked you in this block any other comments about it or so?

P: Well, eh, it is very interesting that some people are just doing research on the way different methods could be developed to understand how data fabrication is done. And if we could also be informed about - I mean the detection of the fabrication in the data I would be very much thankful.

I: Ok, then this is the end of the interview or is there anything else you can recall about the data fabrication process that you think is worth mentioning?

P: Well, I think I have mentioned everything about it.
