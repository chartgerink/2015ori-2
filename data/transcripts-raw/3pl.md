### Legend

1. [REDACTED] means that the original word/fragment was deleted to ensure the anonymity of the participants.

2. [?] is a placeholder for words/fragments that could not be transcribed.

3. (?) means that the transcriber was not completely sure what the last word/fragment was, but had a guess.

4. Sentences that begin with "I:" were said by the interviewer

5. Sentences that begin with "P:" were said by the participat


### Block 1: General Information

I: Ok. So, then we will start with the first block. The goal of this block is to get some general information about you. So, the first question is: Are you a PhD Student?

P: Yes. 

I: Ok. And what is your field within psychology? For instance social or cognitive psychology? 

P: Social psychology.

I: Ok. And did you conduct any experiments including a Stroop task in your career?

P: No.

I: Could you describe a bit your experience with the Stroop task or your knowledge about the Stroop task?

P: So, I have been taught on the Stroop task in my Bachelor years. Just during the regular program. And I have read some articles on it. But I have never conducted a study in any form. I have never seen data on the Stroop task.

I: Ok. And which statistical analysis programs do you use at least once a week? Multiple answers are possible. For instance, SPSS, R, Stata, SAS, Matlab, Python, or any other? 

P: Typically R. Sometimes for my students SPSS.

I: Ok. And how would you rate your knowledge of statistics relative to your peers on a scale from 1 extremely poor, to 10, excellent?

P: 8.

I: Ok. And how confident are you that your fabricated data will go undetected as fabricated? On a scale from 1, extremely insecure, to 10, extremely confident. 

P: That is more difficult. 5.


### Block 2: Timeline of Data Fabrication Process (When?)

I: Ok. Then this is is the end of the first block about general information. Now, we will start with the second block. The goal of this block is to get some information about the timeline of the data fabrication process. So, the first question is: Did you fabricate the data in one day or spread the data fabrication over several days?

P: One day.

I: One day, ok. And how much time do you estimate that it took you to fabricate the data in their entirety? 

P: That is a good question. The actual data fabrication took me about an hour. But then I got so interested that I spent another hour on seeing if there were ways that I could optimize it. So, I spent two hours on this(?).

I: Ok. And how much effort do you feel you invested in fabricating the data on a scale from 1 (no effort at all) to 7 (a lot of effort)? 

P: 4.

I: Ok. Did you prepare in any way before starting to fabricate the data?

P: What kind of preparation? I don't think so.

I: So, for instance, did you read literature on detecting data fabrication?

P: No. I did that after the data fabrication, though.

I: Ok. Could you describe or name the methods you read about?

P: I didn't find much. That was the problem. But I mostly checked some stuff that I already knew existed. So, stuff on what kind of variation was likely, what the chances were of finding a significant effect in such a small sample. That kind of stuff. But I didn't find any specific article on data fabrication or how to detect it.

I: Ok. And did you maybe look into previous cases of data fabrication and how they had been detected? 

P: Nope. 

I: Ok. Did you prepare in any other ways? Like did you spend some time on this study before you actually started to work on how to fabricate the data?

P: Yeah, I thought about multiple ways in which you could fabricate the data. So, whether to use like an existing data set or start from scratch. I also thought about what would be - what would make a dataset not look very clean. What else? I think that's it.

I: Ok, thank you. Then this is the end of the second block. Do you have any other comments about the timeline of the data fabrication process that you think could be interesting for us to know? 

P: No.
  

### Block 3: Broad Framework of Data Fabrication Process (What?)

I: Ok. Then, we will now start with the third block. The goal of this block is to get some information about the broad framework of the data fabrication process. So, the first question is: Could you name specific characteristics that would make data look fabricated or more fabricated in your opinion?

P: If the data looks to clean. So, for example, no outliers. If the differences are extremely big. Let me see. If - for example the effect size or means differ a lot from other studies in that field. So, for example, if the means would be way higher than in real data. I think that's it.

I: So, you mentioned before that you searched for literature on the variability of possible results or so. Is that also related to the characteristics here?

P: Yeah, I think so. For example, the standard deviation should be in line with the number of trials you have. So, knowing that the standard deviation gets typically smaller if you have more trials per participant. That is definitely something I would think about. I think that is the most relevant one, yeah.

I: Ok. And could you name specific characteristics that would make data look genuine or more genuine in your opinion?

P: I think the opposite. So, an outlier. Means that look similar to other studies. An effect size that is in line with other studies. Not necessarily the same but in line with other studies. Yeah, I thought about missing values but that is in this case not really relevant. 

I: And did you take these characteristics you just mentioned into account when fabricating the data?

P: Yes.

I: Ok and how did you do that?

P: So, for example, the outliers that - So, I used an existing data set as the basis of my fabricated data. And the outliers in that study I left in there. Or at least I tweaked them but they are still in there. Also in terms of standard deviations. Some were really low and some were really high and I kept some of them in there. And also because the standard deviations of the congruent trials were based on 20 trials instead of the 30 that we had to do, I made all of them a bit smaller. And the one of the incongruent trials were based on 40 trials so I made those all a bit higher for the 30 trials.

I: Ok. And did you take into consideration relations in the data other than the Stroop effect itself?

P: I did check the correlation between the standard deviation and the mean for both - the incongruent and congruent parts. And I tried to keep them similar to the existing dataset that I had. So, for example I saw that the correlation was lower between the standard deviation of the incongruent trials and the mean of the incongruent trials than for the congruent dataset. So, I tried to keep it that way.

I: Ok and what criteria did you use to determine whether you thought your fabricated data would go undetected? 

P: Yeah, I think this is quite similar. So, having outliers in there. Keeping that correlation similar. Not having way smaller standard deviations for the congruent trial than for the incongruent trial or for data points that were outliers. Keeping the means sort of realistic, I guess, or at least related to the existing dataset. Yeah, that's it.

I: Ok. And in hindsight, are there things you think you should have paid specific attention to while fabricating the data? 

P: No, I thought a lot about how they are gonna detect it. But since they only want means and standard deviations I couldn't come up with many ways they could detect it. So I had difficulties with that. I thought about how - about whether I should take into account that the p-value maybe should not be too - or basically the t-test should not be too high or the p-value too low. But since almost all of the random samples I took from the existing dataset that I had were super significant I didn't see the point in doing that. So, no. In hindsight no other things I would have done, no.

I: Ok, then this is the end of the third block. Do you have any other comments about the broad framework of the data fabrication that you think could be interesting for us to know?

P: Nope.


### Block 4: Specific Steps of Data Fabrication Process (How?)

I: Then, we will now start with the fourth block. The goal of this block is to get some information about the specific steps of the data fabrication process. So, could you indicate what steps you took to fabricate the means for the participants?

P: So, I used an existing dataset from the many labs open data. So, I took that dataset and then I drew a random sample of 25 participants from that data. I made sure not to take outliers out which is what they typically do when cleaning the data. I also didn't check for missing values. So, I just made the means based on that random sample. Then took those means and added some error.

I: How did you add the error?

P: I added the error by changing the means but not too much. Because I didn't want to destroy the effect, basically. I took the means that I had and then just changed them a little bit so that the mean at the end would still be quite the same. And I also did this together with the standard deviations. So, just to make sure that those correlations would be quite similar. If I increased one, then I also tried to increase the other. Although not necessarily by exactly the same number or relative number, no.

I: And did you do this like by yourself or did you like have a computer program to simulate how much noise you want to add or ...?

P: No, I did it by myself because I didn't want any structural changes that could be detected.

I: Ok. And could you indicate what steps you took to fabricate the standard deviations for the participants? 

P: Yeah, similar to the means. So, I also took the same participants - also a random set from the many labs dataset. And these are the same participants as for the means. And I also put those in a datafile and tweaked them together with the means. Also, just myself.

I: Ok. And did you repeatedly fabricate data until you were satisfied with the results? 

P: Yeah. I checked in between a few times if the test statistic changed too much or not. And I checked the correlations between means and standard deviations. I checked if the means differed a lot in the end from the random samples I took. And then changed based on that a bit.

I: Ok. Could you describe in a bit more detail how you determined whether you were satisfied with the fabricated data or that they needed to be adjusted?

P: Yeah, in the beginning I changed the - so first, when I changed the means - of course when I changed the means of the congruent to one (?) and made them all a bit faster - is that true? yeah congruent a bit faster - so I noticed quite quickly that that results in of course in an average mean that is way smaller. So then I changed it against a bit up - some of them. So, some of them more in the other direction to make sure that the overall mean would in the end be similar to the dataset that I used. And I did the same for the standard deviations. So, I didn't want it to be too odd. I made the standard deviations of the congruent trials smaller. So, I also checked if that overall was the case. And if it became way smaller or not (?).

I: Ok and did you try to inspect whether the fabricated data looked weird? 

P: Well, actually, I thought it looked weird with some of the outliers. But I thought that was a good sign, actually. So, I had, for example, a standard deviation that was super low compared to the others but I kept it in there.

I: Ok and did you try to inspect whether the fabricated data looked genuine?

P: Yes. So what I noticed was that some of the means or standard deviations were quite similar in their exact number. And I tried to keep it that way in the new dataset as well.

I: Ok, and how many different mean-sd combinations did you fabricate before getting to the final fabricated dataset?

P: 4. 

I: Ok. And besides the supplied spreadsheet, did you use any other computer programs to fabricate data?

P: R.

I: Did you use a random number generator to simulate data during this study?

P: No.

I: Ok and did you use real data during the fabrication process?

P: Yes.

I: Ok and how much real data did you use?

P: Well, all of it is based on real data. But in the end, I think none of the numbers are exactly the same as in the dataset that I used. 

I: Ok, then this is the end of the fourth block. Do you have any other comments about the specific steps of the data fabrication process that you think could be interesting for us to know? 

P: No, I don't think so. No.


### Block 5: Underlying Rationale of Data Fabrication Process (Why?)

I: Then, we will now start with the fifth block. The goal of this block is to get some information about the underlying rationale of the data fabrication process. So, the first question is: Did you consider fabricating these data a difficult task to complete?

P: No.

I: Why not?

P: I thought of it more as a challenge in that way which sounds horrible maybe. No, it is nice because for me it felt like a test of my own knowledge in stats, actually. I couldn't come up with many ways they could detect it. So, I was also very enthusiastic about helping and then in the end finding out how they did it. Anything else? No, that's it.

I: Ok. And do you think that your approach to data fabrication will be difficult to detect as fabricated?

P: No, I think the fact that I used data that is openly available could make it easier to detect it. If that is used as a basis to test against then I can see how my data could be detected. But because I used existing data and an existing data set my data does look real in that sense. So, yes and no. Yes in the sense that if they use it as a basis then it will be easier, I think. But if I would send it to a journal, I think no becasue it looks real.

I: Ok. And why did you decide to participate in this study? 

P: I think it is a very interesting idea. [REDACTED]. So, in that sense, I think it is also really good if they have a way to test this. And to test if data is real or not. Then, that would be great. Also, the challenge in it was nice, I think. I kind of liked doing it. Sounds horrible but(?) I kind of liked it. But mostly because of hoping that there is a way that they can detect this stuff.

I: Ok. And did you discuss this study or the fabrication of the dataset for this study with other people?

P: Yes. I discussed it because I know that others that I know are also participating in this. But we also made clear to each other that we didn't want to say what we are using. But we were talking about it like what kind of methods would they use to detect it. None of us could come up with a good way it could be detected. So, we didn't share much information in that sense.

I: Ok, so did these people help you in fabricating the data?

P: No.

I: Ok. Then this is the end of the fifth block. Do you have any other comments about the underlying rationale of the data fabrication process that you think could be interesting for us to know?

P: No.

I: Ok, then this is the end of the interview or is there anything else you can recall about the data fabrication that you think is worth mentioning?

P: I felt challanged in the data fabrication and on the one hand I hoped that I would not be detected but on the other hand I was also afraid that I would be too good at this. So I am not sure what is the compliment - being good at this or being bad at this.
