### Legend

1. [REDACTED] means that the original word/fragment was deleted to ensure the anonymity of the participants.

2. [?] is a placeholder for words/fragments that could not be transcribed.

3. (?) means that the transcriber was not completely sure what the last word/fragment was, but had a guess.

4. Sentences that begin with "I:" were said by the interviewer

5. Sentences that begin with "P:" were said by the participat


### Block 1: General Information

I: So, now we start with the first block. The goal of this block is to get some general information about you. So, the first question is: Are you a PhD Student?

P: Yes.

I: And what is your field within psychology? For example, social or cognitive psychology.

P: Social psychology.

I: Social psychology, ok. And did you conduct any experiments including a Stroop task in your career?

P: I did conduct experiments but not the Stroop task, I think, no.

I: And like, in general, what is your experience or knowledge about the Stroop task is?

P: I learned about it in my Bachelor psychology and Research Master program as well. So, I know what the idea is and how it is conducted.

I: Ok. And which statistical analysis programs do you use at least once a week? Multiple answers are possible. For instance, SPSS, R, Stata, SAS, Matlab, Python, or any other? 

P: Once a week - more than once a week, I use R. Less than that I use SPSS. Yeah, mostly R.

I: Ok. And how would you rate your knowledge of statistics relative to your peers on a scale from 1, extremely poor, to 10, excellent?

P: To my peers? Let's say 8.

I: 8, ok. Let me just see, yeah still running ok. And how confident are you that your fabricated data will go undetected as fabricated? Again on a scale from 1 to 10 where 1 means extremely insecure and 10 means extremely confident. 

P: 7.
 
### Block 2: Timeline of Data Fabrication Process (When?)

I: 7, ok. Then this is is the end of the first block about general information. Now, we will start with the second block. The goal of this block is to get some information about the timeline of the data fabrication process. So, the first question is: Did you fabricate the data in one day or spread the data fabrication over several days?

P: The actual fabrication: one day. I thought about it a little before that. But the process itself took one day.

I: And like including the days that you thought about it, on how many days did you work on fabricating the data?

P: I think, 3 days.

I: 3 days, ok. And how much time do you estimate that it took you to fabricate the data in their entirety? 

P: I think maybe two and a half hours. Something like that.

I: Ok. And how much effort do you feel you invested in fabricating the data on a scale from 1 (no effort at all) to 7 (a lot of effort)? 

P: 6.

I: 6, ok. Did you prepare in any way before starting to fabricate the data?

P: Yeah. As I said, I thought a little bit about different strategies that I could use. I thought about looking things up but didn't do so in the end. No. So, mostly thinking about it.

I: And how much time do you estimate you spent on preparing?

P: Half an hour - or something.

I: Ok. And did you read any literature on detecting data fabrication?

P: No.

I: Ok. Did you look into previous cases of data fabrication and how they had been detected? 

P: No.

I: Ok. And, so you said that you thought about different strategies. Could you like elaborate on like how these strategies looked like?

P: My first idea was of just generating or simulating data based on the statistics of existing experiments. So, for example, generating data that has a particular mean and standard deviation for the two conditions. So, that basically was my first idea. But then I thought, ok, there is probably all kinds of aspects of this data that I don't know about besides just having a proper mean and sd. So, that's probably not gonna work. Maybe, I should just use existing data and then make sure that they don't find out that it is existing data.

I: Ok. And did this preparation influence your approach to fabricating the data? 

P: Ja. Basically, as I said, instead of simulating data I decided to use existing data.

I: Ok. Then this is the end of the second block. Do you have any other comments about the timeline of the data fabrication process that you think could be interesting for us to know? 

P: No, I don't think so.


### Block 3: Broad Framework of Data Fabrication Process (What?)

I: Ok. Then, we will now start with the third block. The goal of this block is to get some information about the broad framework of the data fabrication process. So, the first question is: Could you name specific characteristics that would make data look fabricated or more fabricated in your opinion?

P: I have heard of some cases in which, for example, the effects were too perfect in some ways. So, for example, a study with three conditions in which the means were exactly linear. Or another flag that I have heard about in relation to the Diederik Stapel case was data that was obviously copy-pasted so that you get the same means or standard deviations or whatever. Other stuff I heard about was that people are very bad at just randomly generating data themselves. So, just entering numbers in Excel, I knew, was probably not going to work because I would probably not be able to generate enough - or proper randomness myself. So, those were the main factors I thought about but, yeah as I said, I also thought that my - there is probably more that I don't know about. So, yeah.

I: Ok. And could you name specific characteristics that would make data look genuine or more genuine in your opinion?

P: Yeah. First, basically, just the absence of the things I just mentioned. So, no too perfect data, no copy-pasted data, obviously, no data that has some kind of pattern in it in a way. And there might be more but I don't know.

I: Ok. And did you take these characteristics you just mentioned into account when fabricating the data?

P: Indirectly, basically. If I would have simulated the data, I would have thought more about them. But now I just did it indirectly by making sure that I had real data which should have these characteristics.

I: And did you take into consideration relations in the data other than the Stroop effect itself? 

P: Sorry, I am not sure I understand the question.

I: So, like, did you take into consideration relations in the data other than the Stroop effect itself? For example, the distribution of the scores or other aspects that could be inspected with the data set.

P: Again, not directly because I just used existing data on this. But I can imagine, for example, that scores - eh the congruent trials and incongruent trials scores highly correlate within-participants. So, that is something I thought about but, again, did not directly influence.

I: Ok, and what criteria did you use to determine whether you thought your fabricated data would go undetected? 

P: Yeah, basically, I think, the only thing I used was existing data. Oh and I added a little bit of error to the existing data so - yeah, probably it wouldn't have been possible but I wanted to make sure that you couldn't compare my data set to this existing data set and then find the specific cases I used. So (?), I added a little bit of random error.

I: Ok. And in hindsight, are there things you think you should have paid specific attention to while fabricating the data? 

P: One thing I had difficulties with was that the data set I found was a data set from many labs had only 21 congruent trials per participant and your task required 25. So, I think that with more trials the standard deviation becomes lower. So, probably, my standard deviation is a little higher than on average in this kind of tasks but I didn't find - or I couldn't find a good way to change that so I just left it like it was. But that is probably an imperfection.

I: Ok, then this is the end of the third block. Do you have any other comments about the broad framework of the data fabrication that you think could be interesting for us to know?

P: One other thing I wasn't sure about: The task said to report the means and standard deviations in milliseconds. So, I rounded them to full numbers but I wasn't sure if that was the - yeah whether I was supposed to do that.


### Block 4: Specific Steps of Data Fabrication Process (How?)

I: Ok. Then, we will now start with the fourth block. The goal of this block is to get some information about the specific steps of the data fabrication process. So, could you indicate what steps you took to fabricate the means for the participants?

P: Jep. I downloaded a data set from the many labs on Open Science Framework. I, then, took - eh sampled 25 sessions - so data from 25 participants from this data set. And for each participant, I only kept the first 21 congruent trials and the first 21 incongruent trials. And then, basically, for each of these 21 trials for each participant, I calculated the mean.

I: Ok. And could you indicate what steps you took to fabricate the standard deviations for the participants? 

P: Jep. I took the same data that I sampled for the means and then calculated the standard deviation for each participant.

I: Ok. And you said that you added some random noise ...

P: Yeah, oh, yeah. And after I calculated the means and standard deviations I added a little bit of error to each mean score and each standard deviation. I didn't really know what numbers I should use. So, I just picked - eh sampled from a random distribution with a mean of 0 and standard deviation of 10 for the means. And a mean of 0 and standard deviation of 3 for the standard deviations. As these just seemed like good numbers.

I: And what distribution did you use? Like a normal distribution ...

P: Yeah, a normal distribution, yeah.

I: Ok and like you - so like the means and standard deviations for the normal distribution  based on what you thought might be like good numbers or?

P: Yeah. I wanted just random noise and I thought this would be one way to do it.

I: Ok. And did you repeatedly fabricate data until you were satisfied with the results? 

P: No. I just - I picked - so, for the random sampling, I picked a seed number which I just used and then I only, basically, looked at the results after I ran all the numbers. I might have done it again and pick a different seed number if the results were not significant because the results needed to be significant for the task. But in this case, they were, so I didn't need to change anything.

I: And - ok, so, the next question is: How did you determine whether you were satisfied with the fabricated data or that they needed to be adjusted?

P: Yeah, basically, the only thing I looked at was whether the result was significant or not.

I: Ok and did you try to inspect whether the fabricated data looked weird in a way? 

P: I did look to see if there was some variation at least in the means and in the standard deviations. Also to make sure that I didn't make any errors. But I didn't really look at how random it seemed or anything. I just trusted the procedure.

I: And did you try to inspect whether the fabricated data looked genuine in any way?

P: Yeah, again, not really, no.

I: Ok, and how many different mean-sd combinations did you fabricate before getting to the final fabricated dataset?

P: Yeah, basically, it was just this one. I did first run it a few times without setting a seed but then I thought it is probably better to set a seed so that they can reproduce my exact analysis. So yeah, I did try some stuff but never really for real, so to speak.

I: Ok. And besides the supplied spreadsheet, did you use any other computer programs to fabricate data?

P: R, ja.

I: Ok. And ... ja, sorry?

P: Oh ja, ... and I used Excel but just to copy-paste in the values, I think. So, no.

I: And did you use a random number generator to simulate data during this study?

P: Yeah. I used a random number generator to generate the noise that I added.

I: And yeah, the next question is ...

P: Oh and also to sample by the way. To sample from the data. That was also random, of course.

I: Ok. And the next question is: Did you use real data during the fabrication process?

P: Yes.

I: Ok. And how much real data did you use?

P: So, yeah. All the - I started with only real data and then added some simulated noise.

I: Ok, then this is the end of the fourth block. Do you have any other comments about the specific steps of the data fabrication process that you think could be interesting for us to know? 

P: No, that was it.


### Block 5: Underlying Rationale of Data Fabrication Process (Why?)

I: Ok. Then, we will now start with the fifth and final block. The goal of this block is to get some information about the underlying rationale of the data fabrication process. So, did you consider fabricating these data a difficult task to complete?

P: The actual like procedure wasn't very difficult. But coming up with a good idea was fairly (?) difficult.

I: Ok. And do you think that your approach to data fabrication will be difficult to detect as fabricated?

P: I think so. But that's mainly because I cannot think of any ways to detect it myself. But there is probably ways that I don't know about that might work here.

I: Ok. And why did you decide to participate in this study? 

P: One, because I think it is fun. I like to play around with data. Two, because, I think, 100 Euros is a nice incentive. And three, also because I like the idea of competition.

I: Ok. And did you discuss this study or the fabrication of the dataset for this study with other people?

P: Only after I was completely done with all the creation of the data.

I: Ok. So, did these people help you in fabricating the data?

P: No.

I: Ok. Then this is the end of the fifth block. Do you have any other comments about the underlying rationale of the data fabrication process that you think could be interesting for us to know?

P: No, I don't think so.

I: Ok, then this is the end of the interview or is there anything else you can recall about the data fabrication that you think is worth mentioning?

P: I did feel a bit excited or nervous during the data fabrication. And I thought about it. I thought it is probably for three reasons. One is, it felt a little bit wrong. Just, you know, the idea of creating your own data. But also because I wasn't sure whether I was allowed to use real data. It didn't really say so in the task. But also it is like - it is not simulating and (?) actually creating new data. And three, because of the competetive element, it was also more exciting than just, you know, doing some random stuff.
